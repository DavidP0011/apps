{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidP0011/apps/blob/main/app_transc_01_files_path_collect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INICIALIZACIÃ“N"
      ],
      "metadata": {
        "id": "nxXmQcqu9E_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title dpm_ini_utils.py (GitHub)\n",
        "\n",
        "import os         # Para operaciones del sistema y manejo de rutas.\n",
        "import sys        # Para interactuar con el sistema, en particular con sys.path.\n",
        "import importlib  # Para realizar importaciones dinÃ¡micas.\n",
        "import tempfile   # Para crear archivos temporales.\n",
        "import requests   # Para realizar peticiones HTTP y descargar el mÃ³dulo.\n",
        "\n",
        "# URL raw del mÃ³dulo en GitHub (debe incluir las funciones ini_load_dpm_libs, ini_environment_identification e ini_google_drive_instalation)\n",
        "github_url = \"https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_ini_utils.py\"\n",
        "\n",
        "# Solicitar la descarga sin utilizar cachÃ©, para asegurar que se obtiene la versiÃ³n actualizada.\n",
        "headers = {\"Cache-Control\": \"no-cache\", \"Pragma\": \"no-cache\"}\n",
        "response = requests.get(github_url, headers=headers)\n",
        "if response.status_code != 200:\n",
        "    raise Exception(f\"Error al descargar el mÃ³dulo desde GitHub. CÃ³digo: {response.status_code}\")\n",
        "\n",
        "# Guardar el contenido descargado en un archivo temporal.\n",
        "temp_dir = tempfile.gettempdir()\n",
        "module_path = os.path.join(temp_dir, \"dpm_ini_utils.py\")\n",
        "with open(module_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Agregar el directorio temporal a sys.path si aÃºn no estÃ¡ incluido, para permitir la importaciÃ³n.\n",
        "if temp_dir not in sys.path:\n",
        "    sys.path.insert(0, temp_dir)\n",
        "\n",
        "# Invalidar cachÃ©s y eliminar versiones previas del mÃ³dulo para forzar la recarga.\n",
        "importlib.invalidate_caches()\n",
        "module_name = \"dpm_ini_utils\"\n",
        "if module_name in sys.modules:\n",
        "    del sys.modules[module_name]\n",
        "\n",
        "# Importar y recargar el mÃ³dulo.\n",
        "module = importlib.import_module(module_name)\n",
        "module = importlib.reload(module)\n",
        "\n",
        "# Intentar importar las funciones deseadas desde el mÃ³dulo.\n",
        "ini_install_libraries = getattr(module, \"ini_install_libraries\", None)\n",
        "ini_load_dpm_libs = getattr(module, \"ini_load_dpm_libs\", None)\n",
        "ini_environment_identification = getattr(module, \"ini_environment_identification\", None)\n",
        "ini_google_drive_instalation = getattr(module, \"ini_google_drive_instalation\", None)\n",
        "\n",
        "# Verificar que las funciones se hayan importado correctamente.\n",
        "if ini_install_libraries is None:\n",
        "    print(\"La funciÃ³n ini_install_libraries no se encontrÃ³ en el mÃ³dulo.\")\n",
        "else:\n",
        "    print(\"FunciÃ³n ini_install_libraries cargada correctamente.\")\n",
        "\n",
        "if ini_load_dpm_libs is None:\n",
        "    print(\"La funciÃ³n ini_load_dpm_libs no se encontrÃ³ en el mÃ³dulo.\")\n",
        "else:\n",
        "    print(\"FunciÃ³n ini_load_dpm_libs cargada correctamente.\")\n",
        "\n",
        "if ini_environment_identification is None:\n",
        "    print(\"La funciÃ³n ini_environment_identification no se encontrÃ³ en el mÃ³dulo.\")\n",
        "else:\n",
        "    print(\"FunciÃ³n ini_environment_identification cargada correctamente.\")\n",
        "\n",
        "if ini_google_drive_instalation is None:\n",
        "    print(\"La funciÃ³n ini_google_drive_instalation no se encontrÃ³ en el mÃ³dulo.\")\n",
        "else:\n",
        "    print(\"FunciÃ³n ini_google_drive_instalation cargada correctamente.\")\n"
      ],
      "metadata": {
        "id": "EPbRzlCq9Clc",
        "outputId": "b468464a-692d-4b78-87a6-90e18956cfab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FunciÃ³n ini_install_libraries cargada correctamente.\n",
            "FunciÃ³n ini_load_dpm_libs cargada correctamente.\n",
            "FunciÃ³n ini_environment_identification cargada correctamente.\n",
            "FunciÃ³n ini_google_drive_instalation cargada correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title IDENTIFICACION DE ENTORNO, INSTALACIÃ“N GOOGLE DRIVE\n",
        "\n",
        "# Detectar el entorno de ejecuciÃ³n\n",
        "ini_environment_identificated = ini_environment_identification()\n",
        "print(f\"[INFO â„¹ï¸] Entorno detectado: {ini_environment_identificated}\", flush=True)\n",
        "\n",
        "GCP_json_keyfile_local = r\"C:/api_keys/XXX.json\"\n",
        "GCP_json_keyfile_colab = \"/content/drive/MyDrive/ANIMUM DIRECCION/DIRECCION BI/NOTEBOOKS/api_keys/animum-dev-apps-google-colab.json\"\n",
        "GCP_json_keyfile_GCP_secret_id = \"notebook-vm\"\n",
        "\n",
        "# Montar Google Drive si entorno_identificado_str es Colab\n",
        "params = {\"entorno_identificado_str\": ini_environment_identificated}\n",
        "ini_google_drive_instalation(params)"
      ],
      "metadata": {
        "id": "1_UyYEYp9M2a",
        "outputId": "7861f2b5-c970-4663-bf3f-1221c3f5580b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO â„¹ï¸] Entorno detectado: COLAB\n",
            "Mounted at /content/drive\n",
            "[INFO â„¹ï¸] Google Drive montado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title INSTALACION DE LIBRERIAS\n",
        "from IPython import get_ipython\n",
        "import os\n",
        "packages = [\n",
        "    # Ejemplos originales:\n",
        "    {\n",
        "        \"name\": \"whisper\",\n",
        "        \"import_name\": \"whisper\",\n",
        "        # InstalaciÃ³n desde GitHub:\n",
        "        \"install_cmd\": \"pip install git+https://github.com/openai/whisper.git\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"ffmpeg-python\",\n",
        "        \"import_name\": \"ffmpeg\",\n",
        "        \"pip_name\": \"ffmpeg-python\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"FFmpeg\",  # Paquete del sistema\n",
        "        \"is_system\": True,\n",
        "        \"check_cmd\": \"ffmpeg -version\",\n",
        "        \"install_cmds\": [\n",
        "            \"apt-get update\",\n",
        "            \"apt-get install -y ffmpeg\",\n",
        "            \"ffmpeg -version\"\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    {\"name\": \"rapidfuzz\", \"import_name\": \"rapidfuzz\", \"pip_name\": \"rapidfuzz\"},\n",
        "    {\"name\": \"pycountry\", \"import_name\": \"pycountry\", \"pip_name\": \"pycountry\"},\n",
        "    {\"name\": \"phonenumbers\", \"import_name\": \"phonenumbers\", \"pip_name\": \"phonenumbers\"},\n",
        "    {\"name\": \"deep_translator\", \"import_name\": \"deep_translator\", \"pip_name\": \"deep_translator\"},\n",
        "    {\"name\": \"requests\", \"import_name\": \"requests\", \"pip_name\": \"requests\"},\n",
        "    {\"name\": \"beautifulsoup4\", \"import_name\": \"bs4\", \"pip_name\": \"beautifulsoup4\"},\n",
        "    {\"name\": \"googletrans\", \"import_name\": \"googletrans\", \"pip_name\": \"googletrans\", \"version\": \"4.0.0-rc1\"},\n",
        "]\n",
        "\n",
        "# Ejecuta la funciÃ³n para cada paquete\n",
        "for pkg in packages:\n",
        "    ini_install_libraries(pkg)\n"
      ],
      "metadata": {
        "id": "eQoX3eAX9SJY",
        "outputId": "a91373c3-dfd6-481d-fdbf-07edb48ad35d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de whisper...\n",
            "[INSTALLATION [INFO â„¹ï¸]] whisper no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\n",
            "[INSTALLATION [COMMAND â–¶ï¸]] Ejecutando comando personalizado: pip install git+https://github.com/openai/whisper.git\n",
            "[END [FINISHED âœ…]] Proceso de instalaciÃ³n finalizado para whisper.\n",
            "\n",
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de ffmpeg-python...\n",
            "[INSTALLATION [INFO â„¹ï¸]] ffmpeg-python no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\n",
            "[INSTALLATION [COMMAND â–¶ï¸]] Ejecutando: pip install --upgrade ffmpeg-python\n",
            "[END [FINISHED âœ…]] Proceso de instalaciÃ³n finalizado para ffmpeg-python.\n",
            "\n",
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de FFmpeg...\n",
            "[INSTALLATION [SUCCESS âœ…]] FFmpeg ya estÃ¡ instalado.\n",
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de rapidfuzz...\n",
            "[INSTALLATION [INFO â„¹ï¸]] rapidfuzz no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\n",
            "[INSTALLATION [COMMAND â–¶ï¸]] Ejecutando: pip install --upgrade rapidfuzz\n",
            "[END [FINISHED âœ…]] Proceso de instalaciÃ³n finalizado para rapidfuzz.\n",
            "\n",
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de pycountry...\n",
            "[INSTALLATION [INFO â„¹ï¸]] pycountry no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\n",
            "[INSTALLATION [COMMAND â–¶ï¸]] Ejecutando: pip install --upgrade pycountry\n",
            "[END [FINISHED âœ…]] Proceso de instalaciÃ³n finalizado para pycountry.\n",
            "\n",
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de phonenumbers...\n",
            "[INSTALLATION [INFO â„¹ï¸]] phonenumbers no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\n",
            "[INSTALLATION [COMMAND â–¶ï¸]] Ejecutando: pip install --upgrade phonenumbers\n",
            "[END [FINISHED âœ…]] Proceso de instalaciÃ³n finalizado para phonenumbers.\n",
            "\n",
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de deep_translator...\n",
            "[INSTALLATION [INFO â„¹ï¸]] deep_translator no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\n",
            "[INSTALLATION [COMMAND â–¶ï¸]] Ejecutando: pip install --upgrade deep_translator\n",
            "[END [FINISHED âœ…]] Proceso de instalaciÃ³n finalizado para deep_translator.\n",
            "\n",
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de requests...\n",
            "[INSTALLATION [SUCCESS âœ…]] requests ya estÃ¡ instalado.\n",
            "[END [FINISHED âœ…]] Proceso de instalaciÃ³n finalizado para requests.\n",
            "\n",
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de beautifulsoup4...\n",
            "[INSTALLATION [SUCCESS âœ…]] beautifulsoup4 ya estÃ¡ instalado.\n",
            "[END [FINISHED âœ…]] Proceso de instalaciÃ³n finalizado para beautifulsoup4.\n",
            "\n",
            "\n",
            "[START â–¶ï¸] Verificando instalaciÃ³n de googletrans...\n",
            "[INSTALLATION [INFO â„¹ï¸]] googletrans no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\n",
            "[INSTALLATION [COMMAND â–¶ï¸]] Ejecutando: pip install --upgrade googletrans==4.0.0-rc1\n",
            "[END [FINISHED âœ…]] Proceso de instalaciÃ³n finalizado para googletrans.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title IMPORTACIÃ“N DE LIBRERÃAS DPM\n",
        "import sys\n",
        "import os\n",
        "import importlib\n",
        "import datetime\n",
        "import inspect\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# ConfiguraciÃ³n para importar librerÃ­as personalizadas\n",
        "config = [\n",
        "    {\n",
        "        \"module_host\": \"github\",\n",
        "        # Se utiliza la URL raw para obtener el contenido real del archivo\n",
        "        \"module_path\": \"https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_tables.py\",\n",
        "        \"selected_functions_list\": []\n",
        "    },\n",
        "    {\n",
        "        \"module_host\": \"github\",\n",
        "        # Se utiliza la URL raw para obtener el contenido real del archivo\n",
        "        \"module_path\": \"https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_GCP_utils.py\",\n",
        "        \"selected_functions_list\": []\n",
        "    },\n",
        "    {\n",
        "        \"module_host\": \"github\",\n",
        "        \"module_path\": \"https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_SQL.py\",\n",
        "        \"selected_functions_list\": []\n",
        "    }\n",
        "]\n",
        "\n",
        "# Cargar las librerÃ­as personalizadas\n",
        "ini_load_dpm_libs(config)\n"
      ],
      "metadata": {
        "id": "ExZnlgxzN3hT",
        "outputId": "b91e0048-f726-4fa6-b6cb-9ca2de6a91b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”¹ğŸ”¹ğŸ”¹ [START â–¶ï¸] Iniciando carga de mÃ³dulo dpm_tables.py ğŸ”¹ğŸ”¹ğŸ”¹\n",
            "\n",
            "[EXTRACTION [START â–¶ï¸]] Descargando mÃ³dulo desde GitHub: https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_tables.py\n",
            "[EXTRACTION [SUCCESS âœ…]] Archivo descargado y guardado en: /tmp/dpm_tables.py\n",
            "[LOAD [START â–¶ï¸]] Importando mÃ³dulo: dpm_tables\n",
            "[LOAD [SUCCESS âœ…]] MÃ³dulo 'dpm_tables' importado correctamente.\n",
            "\n",
            "[METRICS [INFO ğŸ“Š]] Informe de carga del mÃ³dulo:\n",
            "  - MÃ³dulo: dpm_tables\n",
            "  - Ruta: /tmp/dpm_tables.py\n",
            "  - Fecha de Ãºltima modificaciÃ³n (Ãºltimo commit en GitHub o mod. local): 2025-03-11 17:42:43+01:00\n",
            "  - Objetos importados:\n",
            "      â€¢ fields_name_format (function): Formatea nombres de campos de datos segÃºn configuraciones especÃ­ficas.\n",
            "      â€¢ table_DF_to_various_targets (function): Escribe un DataFrame en distintos destinos (archivo local, Google Sheets, BigQuery o GCS)\n",
            "      â€¢ table_various_sources_to_DF (function): Extrae datos desde distintos orÃ­genes (archivo, Google Sheets, BigQuery o GCS) y los convierte en un DataFrame.\n",
            "\n",
            "[END [FINISHED âœ…]] MÃ³dulo 'dpm_tables' actualizado e importado en los builtins.\n",
            "\n",
            "\n",
            "ğŸ”¹ğŸ”¹ğŸ”¹ [START â–¶ï¸] Iniciando carga de mÃ³dulo dpm_GCP_utils.py ğŸ”¹ğŸ”¹ğŸ”¹\n",
            "\n",
            "[EXTRACTION [START â–¶ï¸]] Descargando mÃ³dulo desde GitHub: https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_GCP_utils.py\n",
            "[EXTRACTION [SUCCESS âœ…]] Archivo descargado y guardado en: /tmp/dpm_GCP_utils.py\n",
            "[LOAD [START â–¶ï¸]] Importando mÃ³dulo: dpm_GCP_utils\n",
            "[LOAD [SUCCESS âœ…]] MÃ³dulo 'dpm_GCP_utils' importado correctamente.\n",
            "\n",
            "[METRICS [INFO ğŸ“Š]] Informe de carga del mÃ³dulo:\n",
            "  - MÃ³dulo: dpm_GCP_utils\n",
            "  - Ruta: /tmp/dpm_GCP_utils.py\n",
            "  - Fecha de Ãºltima modificaciÃ³n (Ãºltimo commit en GitHub o mod. local): 2025-03-11 17:29:30+01:00\n",
            "  - Objetos importados:\n",
            "      â€¢ GBQ_tables_schema_df (function): Retorna un DataFrame con la informaciÃ³n de datasets, tablas y campos de un proyecto de BigQuery,\n",
            "      â€¢ GCS_tables_schema_df (function): Retorna un DataFrame con informaciÃ³n detallada de:\n",
            "\n",
            "[END [FINISHED âœ…]] MÃ³dulo 'dpm_GCP_utils' actualizado e importado en los builtins.\n",
            "\n",
            "\n",
            "ğŸ”¹ğŸ”¹ğŸ”¹ [START â–¶ï¸] Iniciando carga de mÃ³dulo dpm_SQL.py ğŸ”¹ğŸ”¹ğŸ”¹\n",
            "\n",
            "[EXTRACTION [START â–¶ï¸]] Descargando mÃ³dulo desde GitHub: https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_SQL.py\n",
            "[EXTRACTION [SUCCESS âœ…]] Archivo descargado y guardado en: /tmp/dpm_SQL.py\n",
            "[LOAD [START â–¶ï¸]] Importando mÃ³dulo: dpm_SQL\n",
            "[LOAD [SUCCESS âœ…]] MÃ³dulo 'dpm_SQL' importado correctamente.\n",
            "\n",
            "[METRICS [INFO ğŸ“Š]] Informe de carga del mÃ³dulo:\n",
            "  - MÃ³dulo: dpm_SQL\n",
            "  - Ruta: /tmp/dpm_SQL.py\n",
            "  - Fecha de Ãºltima modificaciÃ³n (Ãºltimo commit en GitHub o mod. local): 2025-03-11 17:34:28+01:00\n",
            "  - Objetos importados:\n",
            "      â€¢ DF_to_GBQ (function): Carga un DataFrame en una tabla de Google BigQuery e imprime un informe detallado con\n",
            "      â€¢ GBQ_execute_SQL (function): Ejecuta un script SQL en Google BigQuery y muestra un resumen detallado con estadÃ­sticas del proceso.\n",
            "      â€¢ SQL_generate_BI_view_str (function): Crea o reemplaza una vista (o tabla) BI, seleccionando columnas de una tabla fuente con mapeos y filtros.\n",
            "      â€¢ SQL_generate_CPL_to_contacts_str (function): Genera una sentencia SQL para crear o reemplazar una tabla que combina una tabla principal de contactos,\n",
            "      â€¢ SQL_generate_academic_date_str (function): Genera una sentencia SQL para crear o reemplazar una tabla con campos de fecha acadÃ©mica/fiscal,\n",
            "      â€¢ SQL_generate_cleaning_str (function): Genera una sentencia SQL para crear o sobrescribir una tabla de 'staging' aplicando mapeos, filtros\n",
            "      â€¢ SQL_generate_country_from_phone (function): Genera un script SQL para actualizar una tabla destino a partir de datos extraÃ­dos y procesados de:\n",
            "      â€¢ SQL_generate_country_name_mapping (function): FunciÃ³n unificada que:\n",
            "      â€¢ SQL_generate_deal_ordinal_str (function): Genera un script SQL que crea o reemplaza una tabla con un campo ordinal de negocio por contacto,\n",
            "      â€¢ SQL_generate_join_tables_str (function): Crea o reemplaza una tabla uniendo una tabla primaria, secundaria y opcionalmente una tabla puente,\n",
            "      â€¢ SQL_generate_new_columns_from_mapping (function): Genera un script SQL que agrega nuevas columnas a una tabla de BigQuery a partir de un mapeo\n",
            "      â€¢ SQL_generation_normalize_strings (function): Normaliza los valores de una columna en una tabla de BigQuery usando mapeo manual y fuzzy matching.\n",
            "\n",
            "[END [FINISHED âœ…]] MÃ³dulo 'dpm_SQL' actualizado e importado en los builtins.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "U-hU3wVkrKz3",
        "outputId": "bd0c1712-9bd9-4e55-b933-7583d1d9dfce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El paquete 'whisper' no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-fmgh_a8f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-fmgh_a8f\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2->openai-whisper==20240930) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m154.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m171.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803669 sha256=88f206d028867cbcd4d5b855487f323cbe52f45a27422b3c80ede674ada16e8e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nxb4ql3w/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n",
            "El paquete 'ffmpeg-python' no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "FFmpeg ya estÃ¡ instalado.\n"
          ]
        }
      ],
      "source": [
        "# @title IMPORTACIÃ“N DE LIBRERÃAS WHISPER Y FFMPEG\n",
        "\n",
        "# Verificar e instalar el paquete 'whisper'\n",
        "try:\n",
        "    import whisper\n",
        "except ImportError:\n",
        "    print(\"El paquete 'whisper' no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\")\n",
        "    !pip install git+https://github.com/openai/whisper.git\n",
        "    import whisper\n",
        "\n",
        "# Verificar e instalar el paquete 'ffmpeg-python'\n",
        "try:\n",
        "    import ffmpeg\n",
        "except ImportError:\n",
        "    print(\"El paquete 'ffmpeg-python' no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\")\n",
        "    !pip install ffmpeg-python\n",
        "\n",
        "# Instalar y verificar 'ffmpeg' a nivel del sistema\n",
        "import os\n",
        "if os.system(\"ffmpeg -version\") != 0:\n",
        "    print(\"FFmpeg no estÃ¡ instalado. Procediendo con la instalaciÃ³n...\")\n",
        "    !apt-get update\n",
        "    !apt-get install -y ffmpeg\n",
        "    !ffmpeg -version\n",
        "else:\n",
        "    print(\"FFmpeg ya estÃ¡ instalado.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GBQ DATASETS SCHEMA"
      ],
      "metadata": {
        "id": "Teu_Q7OxO5nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GBQ INFO GLOBAL\n",
        "\n",
        "\n",
        "# ConfiguraciÃ³n\n",
        "params_dic = {\n",
        "    \"spreadsheet_source_table_id\": \"1aJCGTJtDu_ODqBc4zUcrpQ-q6PE_HN0rO4mwYMIhCXw\",\n",
        "    \"spreadsheet_source_table_worksheet_name\": \"DATA\",\n",
        "\n",
        "    \"ini_environment_identificated\": ini_environment_identificated,\n",
        "    \"json_keyfile_GCP_secret_id\": GCP_json_keyfile_GCP_secret_id,\n",
        "    \"json_keyfile_colab\": GCP_json_keyfile_colab\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "full_info_from_GBQ_df = table_various_sources_to_DF(params_dic)\n",
        "display(full_info_from_GBQ_df)"
      ],
      "metadata": {
        "id": "6rFSqt23O7ft",
        "outputId": "2b0236bf-89a8-48eb-c748-0014b73e5fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUTHENTICATION [INFO] ğŸ”] Entorno local/Colab detectado. Usando json_keyfile_colab.\n",
            "[EXTRACTION [START â³]] Extrayendo datos de Google Sheets...\n",
            "[EXTRACTION [SUCCESS âœ…]] Datos extraÃ­dos con Ã©xito de la hoja 'DATA'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    project_id     dataset_id       table_name  \\\n",
              "0     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "1     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "2     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "3     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "4     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "...                        ...            ...              ...   \n",
              "9688  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "9689  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "9690  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "9691  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "9692  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "\n",
              "                field_name field_type  num_rows num_columns size_mb  \\\n",
              "0                   nconst     STRING  14235647           6  865.54   \n",
              "1              primaryName     STRING  14235647           6  865.54   \n",
              "2                birthYear    INTEGER  14235647           6  865.54   \n",
              "3                deathYear     STRING  14235647           6  865.54   \n",
              "4        primaryProfession     STRING  14235647           6  865.54   \n",
              "...                    ...        ...       ...         ...     ...   \n",
              "9688         Hora_creacion   DATETIME      1033          10    0.06   \n",
              "9689      Usuario_creacion     STRING      1033          10    0.06   \n",
              "9690    Fecha_modificacion   DATETIME      1033          10    0.06   \n",
              "9691     Hora_modificacion   DATETIME      1033          10    0.06   \n",
              "9692  Usuario_modificacion     STRING      1033          10    0.06   \n",
              "\n",
              "     fecha_actualizacion_GBQ fecha_actualizacion_df  \n",
              "0        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "1        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "2        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "3        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "4        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "...                      ...                    ...  \n",
              "9688      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "9689      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "9690      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "9691      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "9692      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "\n",
              "[9693 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad589162-b035-40fe-a861-5d4b2414c657\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project_id</th>\n",
              "      <th>dataset_id</th>\n",
              "      <th>table_name</th>\n",
              "      <th>field_name</th>\n",
              "      <th>field_type</th>\n",
              "      <th>num_rows</th>\n",
              "      <th>num_columns</th>\n",
              "      <th>size_mb</th>\n",
              "      <th>fecha_actualizacion_GBQ</th>\n",
              "      <th>fecha_actualizacion_df</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>nconst</td>\n",
              "      <td>STRING</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>primaryName</td>\n",
              "      <td>STRING</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>birthYear</td>\n",
              "      <td>INTEGER</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>deathYear</td>\n",
              "      <td>STRING</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>primaryProfession</td>\n",
              "      <td>STRING</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9688</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Hora_creacion</td>\n",
              "      <td>DATETIME</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9689</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Usuario_creacion</td>\n",
              "      <td>STRING</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9690</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Fecha_modificacion</td>\n",
              "      <td>DATETIME</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9691</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Hora_modificacion</td>\n",
              "      <td>DATETIME</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9692</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Usuario_modificacion</td>\n",
              "      <td>STRING</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9693 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad589162-b035-40fe-a861-5d4b2414c657')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad589162-b035-40fe-a861-5d4b2414c657 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad589162-b035-40fe-a861-5d4b2414c657');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0f56f4c-814d-408a-af80-1a432a3e4edf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0f56f4c-814d-408a-af80-1a432a3e4edf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0f56f4c-814d-408a-af80-1a432a3e4edf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_52165233-607b-4f70-9d7f-f1f8dbaa6619\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('full_info_from_GBQ_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_52165233-607b-4f70-9d7f-f1f8dbaa6619 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('full_info_from_GBQ_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "full_info_from_GBQ_df",
              "summary": "{\n  \"name\": \"full_info_from_GBQ_df\",\n  \"rows\": 9693,\n  \"fields\": [\n    {\n      \"column\": \"project_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"animum-dev-datawarehouse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"hubspot_raw_v01_hubspot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"table_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 443,\n        \"samples\": [\n          \"stg_hubspot__deal_tmp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3637,\n        \"samples\": [\n          \"active_user_id\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"INTEGER\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_rows\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 323,\n        \"samples\": [\n          \"323\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_columns\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 66,\n        \"samples\": [\n          \"84\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size_mb\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 233,\n        \"samples\": [\n          \"6.83\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fecha_actualizacion_GBQ\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 341,\n        \"samples\": [\n          \"10/03/2025 5:19:57\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fecha_actualizacion_df\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"11/03/2025 17:00:05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GBQ DATASETS\n",
        "print(\"Datasets disponibles:\\n\")\n",
        "for dataset in full_info_from_GBQ_df['dataset_id'].unique():\n",
        "    print(f\"{dataset}\")"
      ],
      "metadata": {
        "id": "zT0CjPsKO9Tt",
        "outputId": "1577218e-5394-4fb4-c4d4-5684f43f2a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets disponibles:\n",
            "\n",
            "IMDb_01raw_01\n",
            "IMDb_02st_01\n",
            "IMDb_raw_01\n",
            "IMDb_staging_01\n",
            "cd2_01raw_01\n",
            "facebook_ads_raw_v01\n",
            "facebook_ads_raw_v01_facebook_ads\n",
            "facebook_ads_raw_v01_facebook_ads_source\n",
            "fivetran_metadata\n",
            "fivetran_metadata_fivetran_platform\n",
            "fivetran_metadata_stg_fivetran_platform\n",
            "google_ads_raw_01\n",
            "google_ads_raw_01_google_ads\n",
            "google_ads_raw_01_google_ads_source\n",
            "hubspot_raw_v01\n",
            "hubspot_raw_v01_hubspot\n",
            "hubspot_raw_v01_stg_hubspot\n",
            "mkt_02st_01\n",
            "mkt_03BI_01\n",
            "tablas_mapeo\n",
            "tp_02st_01\n",
            "tp_03bi_01\n",
            "vl_01raw_01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjCHetu3qgUD"
      },
      "source": [
        "# DECLARACIÃ“N DE FUNCIONES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw6MOjDMlucz"
      },
      "outputs": [],
      "source": [
        "# @title get_video_properties_dic()\n",
        "def get_video_properties_dic(params: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Obtiene las propiedades tÃ©cnicas de un archivo de video.\n",
        "    Args:\n",
        "        params (dict):\n",
        "            - file_path (str): Ruta completa del archivo de video.\n",
        "    Returns:\n",
        "        dict: Diccionario con las siguientes claves:\n",
        "            - file_name (str): Nombre del archivo de video.\n",
        "            - file_path (str): Ruta completa del archivo de video.\n",
        "            - file_size_mb (float): TamaÃ±o del archivo en megabytes.\n",
        "            - duration_s (float): DuraciÃ³n del video en segundos.\n",
        "            - video_codec (str): CÃ³dec de video utilizado.\n",
        "            - audio_codec (str): CÃ³dec de audio utilizado.\n",
        "            - resolution (str): ResoluciÃ³n del video (ancho x alto).\n",
        "            - audio_sample_rate (int): Frecuencia de muestreo del audio en Hz.\n",
        "            - error (str): Mensaje de error en caso de fallo (opcional).\n",
        "    \"\"\"\n",
        "    file_path = params.get(\"file_path\")\n",
        "    try:\n",
        "        probe = ffmpeg.probe(file_path)\n",
        "        video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
        "        audio_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'audio'), None)\n",
        "\n",
        "        return {\n",
        "            \"file_name\": os.path.basename(file_path),\n",
        "            \"file_path\": file_path,\n",
        "            \"file_size_mb\": float(probe['format']['size']) / (1024 * 1024),\n",
        "            \"duration_s\": float(probe['format']['duration']),\n",
        "            \"video_codec\": video_stream['codec_name'] if video_stream else None,\n",
        "            \"audio_codec\": audio_stream['codec_name'] if audio_stream else None,\n",
        "            \"resolution\": f\"{video_stream['width']}x{video_stream['height']}\" if video_stream else None,\n",
        "            \"audio_sample_rate\": int(audio_stream['sample_rate']) if audio_stream else None,\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"file_name\": os.path.basename(file_path),\n",
        "            \"file_path\": file_path,\n",
        "            \"file_size_mb\": None,\n",
        "            \"duration_s\": None,\n",
        "            \"video_codec\": None,\n",
        "            \"audio_codec\": None,\n",
        "            \"resolution\": None,\n",
        "            \"audio_sample_rate\": None,\n",
        "            \"error\": str(e)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt-aVYsgpT1o"
      },
      "outputs": [],
      "source": [
        "# @title orchestrate_transcription_to_GSpread()\n",
        "def orchestrate_transcription_to_GSpread(params: dict):\n",
        "    \"\"\"\n",
        "    Orquesta el proceso de transcripciÃ³n de videos en una carpeta y actualiza\n",
        "    una hoja de Google Sheets con columnas fijas, incluyendo hasta 10 partes\n",
        "    de transcripciÃ³n (de 50k caracteres cada una).\n",
        "\n",
        "    Escribe cada transcripciÃ³n inmediatamente, para no perder avances si\n",
        "    la sesiÃ³n se interrumpe.\n",
        "\n",
        "    Args:\n",
        "        params (dict):\n",
        "            - folder_path (str): Ruta de la carpeta con los videos.\n",
        "            - model_size (str): TamaÃ±o del modelo Whisper (\"tiny\", \"base\", \"small\", \"medium\", \"large\").\n",
        "            - sheet_id (str | None): ID de la hoja de Google Sheets; si no se da, se crea una nueva.\n",
        "            - verbose (bool): Mostrar mensajes detallados durante el proceso.\n",
        "    \"\"\"\n",
        "    import gspread\n",
        "    from google.colab import auth\n",
        "    from google.auth.transport.requests import Request\n",
        "    from google.auth import default\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "    import time\n",
        "    import ffmpeg\n",
        "    import pandas as pd\n",
        "    from whisper import load_model\n",
        "    from IPython.display import display\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 1) Autenticar en Google y abrir/crear la hoja\n",
        "    # ------------------------------------------------------------------------\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    creds.refresh(Request())\n",
        "    gspread_client = gspread.authorize(creds)\n",
        "\n",
        "    sheet_id = params.get(\"sheet_id\")\n",
        "    if sheet_id:\n",
        "        try:\n",
        "            spreadsheet = gspread_client.open_by_key(sheet_id)\n",
        "        except gspread.SpreadsheetNotFound:\n",
        "            raise ValueError(\"El ID proporcionado no corresponde a una hoja vÃ¡lida.\")\n",
        "    else:\n",
        "        folder_name = os.path.basename(params[\"folder_path\"])\n",
        "        sheet_name = \"Transcripciones de Videos\"\n",
        "        spreadsheet = gspread_client.create(f\"{folder_name} - {sheet_name}\")\n",
        "\n",
        "    sheet = spreadsheet.sheet1\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 2) Definir cabecera fija y verificar si la hoja ya la tiene\n",
        "    # ------------------------------------------------------------------------\n",
        "    HEADERS = [\n",
        "        \"file_name\", \"file_path\", \"file_size_mb\", \"duration_s\",\n",
        "        \"video_codec\", \"audio_codec\", \"resolution\", \"audio_sample_rate\",\n",
        "        \"transcription_date\",\n",
        "        \"transcription_part_1\", \"transcription_part_2\", \"transcription_part_3\",\n",
        "        \"transcription_part_4\", \"transcription_part_5\", \"transcription_part_6\",\n",
        "        \"transcription_part_7\", \"transcription_part_8\", \"transcription_part_9\",\n",
        "        \"transcription_part_10\"\n",
        "    ]\n",
        "\n",
        "    existing_values = sheet.get_all_values()\n",
        "    if existing_values:\n",
        "        current_headers = existing_values[0]\n",
        "        # Chequeamos si 'file_name' no existe o si la cantidad de columnas\n",
        "        # es distinta a la que esperamos (19), limpiamos y reescribimos.\n",
        "        if (\"file_name\" not in current_headers) or (len(current_headers) != len(HEADERS)):\n",
        "            sheet.clear()\n",
        "            sheet.update(\"A1\", [HEADERS])\n",
        "    else:\n",
        "        # Hoja en blanco\n",
        "        sheet.update(\"A1\", [HEADERS])\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 3) Leer registros existentes para saber quÃ© archivos se han transcrito\n",
        "    # ------------------------------------------------------------------------\n",
        "    all_rows = sheet.get_all_records()\n",
        "    processed_files = {\n",
        "        row.get(\"file_name\"): row.get(\"transcription_date\", \"N/A\")\n",
        "        for row in all_rows\n",
        "        if row.get(\"file_name\") is not None\n",
        "    }\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 4) Listar archivos y mostrar estado\n",
        "    # ------------------------------------------------------------------------\n",
        "    folder_path = params[\"folder_path\"]\n",
        "    video_files = [\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith((\".mp4\", \".mkv\", \".avi\", \".mov\"))\n",
        "    ]\n",
        "    status_data = []\n",
        "    for video in video_files:\n",
        "        status = \"Transcrito\" if video in processed_files else \"No transcrito\"\n",
        "        date = processed_files.get(video, \"N/A\")\n",
        "        status_data.append({\"file_name\": video, \"status\": status, \"transcription_date\": date})\n",
        "\n",
        "    status_df = pd.DataFrame(status_data)\n",
        "    print(\"\\nEstado de los vÃ­deos:\")\n",
        "    display(status_df)\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 5) Cargar modelo Whisper\n",
        "    # ------------------------------------------------------------------------\n",
        "    model = load_model(params.get(\"model_size\", \"medium\"))\n",
        "    if params.get(\"verbose\", False):\n",
        "        print(f\"\\nModelo '{params.get('model_size', 'medium')}' cargado correctamente.\")\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 6) Transcribir cada video y volcar de inmediato a la hoja\n",
        "    # ------------------------------------------------------------------------\n",
        "    max_chars = 50000  # troceamos la transcripciÃ³n en bloques de 50k para evitar errores en GSheet\n",
        "\n",
        "    for video in video_files:\n",
        "        # Saltar si ya estÃ¡ transcrito\n",
        "        if video in processed_files:\n",
        "            if params.get(\"verbose\", False):\n",
        "                print(f\"Saltando archivo ya procesado: {video}\")\n",
        "            continue\n",
        "\n",
        "        video_path = os.path.join(folder_path, video)\n",
        "\n",
        "        # Obtener metadatos del video (necesita get_video_properties_dic)\n",
        "        properties = get_video_properties_dic({\"file_path\": video_path})\n",
        "\n",
        "        # Transcribir\n",
        "        transcription = \"\"\n",
        "        try:\n",
        "            if params.get(\"verbose\", False):\n",
        "                print(f\"\\nProcesando: {video}\")\n",
        "            result = model.transcribe(video_path, language='es')\n",
        "            transcription = result[\"text\"]\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribiendo {video}: {e}\")\n",
        "            transcription = \"\"\n",
        "\n",
        "        # Trocear en bloques de 50k\n",
        "        transcription_parts = [\n",
        "            transcription[i : i + max_chars]\n",
        "            for i in range(0, len(transcription), max_chars)\n",
        "        ]\n",
        "\n",
        "        # Asignar un mÃ¡ximo de 10 partes\n",
        "        if len(transcription_parts) > 10:\n",
        "            # Concatenar el resto en la Ãºltima parte\n",
        "            sobrante = \"\".join(transcription_parts[10:])\n",
        "            transcription_parts[9] += sobrante\n",
        "            transcription_parts = transcription_parts[:10]\n",
        "\n",
        "        # Preparar lista de 10 partes (rellenando con \"\")\n",
        "        transcription_parts += [\"\"] * (10 - len(transcription_parts))\n",
        "\n",
        "        # Construir la fila en el orden de HEADERS\n",
        "        row_values = [\n",
        "            properties.get(\"file_name\"),\n",
        "            properties.get(\"file_path\"),\n",
        "            properties.get(\"file_size_mb\"),\n",
        "            properties.get(\"duration_s\"),\n",
        "            properties.get(\"video_codec\"),\n",
        "            properties.get(\"audio_codec\"),\n",
        "            properties.get(\"resolution\"),\n",
        "            properties.get(\"audio_sample_rate\"),\n",
        "            datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),   # transcription_date\n",
        "        ] + transcription_parts  # las 10 columnas\n",
        "\n",
        "        # Insertar la fila en la hoja\n",
        "        reintentos = 3\n",
        "        for intento in range(reintentos):\n",
        "            try:\n",
        "                sheet.append_row(row_values, value_input_option=\"USER_ENTERED\")\n",
        "                if params.get(\"verbose\", False):\n",
        "                    print(f\"Actualizado en Google Sheets: {video}\")\n",
        "                break\n",
        "            except gspread.exceptions.APIError as e:\n",
        "                if intento < reintentos - 1:\n",
        "                    print(f\"Error al actualizar Google Sheets. Reintentando ({intento + 1}/{reintentos})...\")\n",
        "                    time.sleep(5)\n",
        "                else:\n",
        "                    print(f\"Error persistente al actualizar Google Sheets: {e}\")\n",
        "\n",
        "    print(f\"\\nProceso completado. Hoja de cÃ¡lculo disponible en: {spreadsheet.url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KV9LQYVLoDFP",
        "outputId": "018ad557-cf57-47d5-edc1-9634738ce902"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Estado de los vÃ­deos:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"orchestrate_transcription_to_GSpread(param)\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"03 - Gestio\\u0301n Financiera 2-20240607_100241.mp4\",\n          \"03 - Gestio\\u0301n Financiera 2 20240607.mp4\",\n          \"04 - Compras y pagos-20240611_115156.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"No transcrito\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcription_date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7ce27598-761e-4ef1-aabe-5e69d0104625\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>status</th>\n",
              "      <th>transcription_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03 - GestioÌn Financiera 2-20240607_100241.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>03 - GestioÌn Financiera 2 20240607.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01 - Ventas y Cobros-20240604_120138 - v1.0 20...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01 - Ventas y Cobros-20240604_100548 - v1.0 20...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07 - SesioÌn anaÌlisis TesoreriÌa  2-20240618_...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>06 - SesioÌn anaÌlisis Tesoreria  1-20240617_1...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>05 - Compras y pagos 2-20240612_113249.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>05 - Compras y pagos 2-20240612_100906.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>04 - Compras y pagos-20240611_115156.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>04 - Compras y pagos-20240611_105212.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>02 - GestioÌn Financiera-20240606_115103.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>02 - GestioÌn Financiera-20240606_103808.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>08 - SesioÌn anaÌlisis Marketing-20240619_1138...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>09 - SesioÌn anaÌlisis Proyectos recursos-2024...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10 - SesioÌn anaÌlisis RRHH-20240710_101033.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>11 - SesioÌn aclarar Dimensiones y Informes Ta...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>12 - ReunioÌn resolucioÌn de dudas-20240712_09...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>13 - SesioÌn trabajo ingresos por moÌdulo-2024...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ce27598-761e-4ef1-aabe-5e69d0104625')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ce27598-761e-4ef1-aabe-5e69d0104625 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ce27598-761e-4ef1-aabe-5e69d0104625');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19f3700a-740d-40fc-88af-cfb36f51c1c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19f3700a-740d-40fc-88af-cfb36f51c1c3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19f3700a-740d-40fc-88af-cfb36f51c1c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            file_name         status  \\\n",
              "0      03 - GestioÌn Financiera 2-20240607_100241.mp4  No transcrito   \n",
              "1             03 - GestioÌn Financiera 2 20240607.mp4  No transcrito   \n",
              "2   01 - Ventas y Cobros-20240604_120138 - v1.0 20...  No transcrito   \n",
              "3   01 - Ventas y Cobros-20240604_100548 - v1.0 20...  No transcrito   \n",
              "4   07 - SesioÌn anaÌlisis TesoreriÌa  2-20240618_...  No transcrito   \n",
              "5   06 - SesioÌn anaÌlisis Tesoreria  1-20240617_1...  No transcrito   \n",
              "6          05 - Compras y pagos 2-20240612_113249.mp4  No transcrito   \n",
              "7          05 - Compras y pagos 2-20240612_100906.mp4  No transcrito   \n",
              "8            04 - Compras y pagos-20240611_115156.mp4  No transcrito   \n",
              "9            04 - Compras y pagos-20240611_105212.mp4  No transcrito   \n",
              "10       02 - GestioÌn Financiera-20240606_115103.mp4  No transcrito   \n",
              "11       02 - GestioÌn Financiera-20240606_103808.mp4  No transcrito   \n",
              "12  08 - SesioÌn anaÌlisis Marketing-20240619_1138...  No transcrito   \n",
              "13  09 - SesioÌn anaÌlisis Proyectos recursos-2024...  No transcrito   \n",
              "14    10 - SesioÌn anaÌlisis RRHH-20240710_101033.mp4  No transcrito   \n",
              "15  11 - SesioÌn aclarar Dimensiones y Informes Ta...  No transcrito   \n",
              "16  12 - ReunioÌn resolucioÌn de dudas-20240712_09...  No transcrito   \n",
              "17  13 - SesioÌn trabajo ingresos por moÌdulo-2024...  No transcrito   \n",
              "\n",
              "   transcription_date  \n",
              "0                 N/A  \n",
              "1                 N/A  \n",
              "2                 N/A  \n",
              "3                 N/A  \n",
              "4                 N/A  \n",
              "5                 N/A  \n",
              "6                 N/A  \n",
              "7                 N/A  \n",
              "8                 N/A  \n",
              "9                 N/A  \n",
              "10                N/A  \n",
              "11                N/A  \n",
              "12                N/A  \n",
              "13                N/A  \n",
              "14                N/A  \n",
              "15                N/A  \n",
              "16                N/A  \n",
              "17                N/A  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.42G/1.42G [00:15<00:00, 95.8MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo 'medium' cargado correctamente.\n",
            "\n",
            "Procesando: 03 - GestioÌn Financiera 2-20240607_100241.mp4\n",
            "Actualizado en Google Sheets: 03 - GestioÌn Financiera 2-20240607_100241.mp4\n",
            "\n",
            "Procesando: 03 - GestioÌn Financiera 2 20240607.mp4\n",
            "Actualizado en Google Sheets: 03 - GestioÌn Financiera 2 20240607.mp4\n",
            "\n",
            "Procesando: 01 - Ventas y Cobros-20240604_120138 - v1.0 20240624.mp4\n",
            "Actualizado en Google Sheets: 01 - Ventas y Cobros-20240604_120138 - v1.0 20240624.mp4\n",
            "\n",
            "Procesando: 01 - Ventas y Cobros-20240604_100548 - v1.0 20240604.mp4\n",
            "Actualizado en Google Sheets: 01 - Ventas y Cobros-20240604_100548 - v1.0 20240604.mp4\n",
            "\n",
            "Procesando: 07 - SesioÌn anaÌlisis TesoreriÌa  2-20240618_100526.mp4\n",
            "Actualizado en Google Sheets: 07 - SesioÌn anaÌlisis TesoreriÌa  2-20240618_100526.mp4\n",
            "\n",
            "Procesando: 06 - SesioÌn anaÌlisis Tesoreria  1-20240617_100524.mp4\n",
            "Actualizado en Google Sheets: 06 - SesioÌn anaÌlisis Tesoreria  1-20240617_100524.mp4\n",
            "\n",
            "Procesando: 05 - Compras y pagos 2-20240612_113249.mp4\n",
            "Actualizado en Google Sheets: 05 - Compras y pagos 2-20240612_113249.mp4\n",
            "\n",
            "Procesando: 05 - Compras y pagos 2-20240612_100906.mp4\n",
            "Error al actualizar Google Sheets. Reintentando (1/3)...\n",
            "Actualizado en Google Sheets: 05 - Compras y pagos 2-20240612_100906.mp4\n",
            "\n",
            "Procesando: 04 - Compras y pagos-20240611_115156.mp4\n",
            "Actualizado en Google Sheets: 04 - Compras y pagos-20240611_115156.mp4\n",
            "\n",
            "Procesando: 04 - Compras y pagos-20240611_105212.mp4\n",
            "Actualizado en Google Sheets: 04 - Compras y pagos-20240611_105212.mp4\n",
            "\n",
            "Procesando: 02 - GestioÌn Financiera-20240606_115103.mp4\n",
            "Actualizado en Google Sheets: 02 - GestioÌn Financiera-20240606_115103.mp4\n",
            "\n",
            "Procesando: 02 - GestioÌn Financiera-20240606_103808.mp4\n",
            "Actualizado en Google Sheets: 02 - GestioÌn Financiera-20240606_103808.mp4\n",
            "\n",
            "Procesando: 08 - SesioÌn anaÌlisis Marketing-20240619_113823.mp4\n",
            "Actualizado en Google Sheets: 08 - SesioÌn anaÌlisis Marketing-20240619_113823.mp4\n",
            "\n",
            "Procesando: 09 - SesioÌn anaÌlisis Proyectos recursos-20240619_100514.mp4\n",
            "Actualizado en Google Sheets: 09 - SesioÌn anaÌlisis Proyectos recursos-20240619_100514.mp4\n",
            "\n",
            "Procesando: 10 - SesioÌn anaÌlisis RRHH-20240710_101033.mp4\n",
            "Actualizado en Google Sheets: 10 - SesioÌn anaÌlisis RRHH-20240710_101033.mp4\n",
            "\n",
            "Procesando: 11 - SesioÌn aclarar Dimensiones y Informes Tableau-20240710_110806.mp4\n",
            "Actualizado en Google Sheets: 11 - SesioÌn aclarar Dimensiones y Informes Tableau-20240710_110806.mp4\n",
            "\n",
            "Procesando: 12 - ReunioÌn resolucioÌn de dudas-20240712_093536.mp4\n",
            "Actualizado en Google Sheets: 12 - ReunioÌn resolucioÌn de dudas-20240712_093536.mp4\n",
            "\n",
            "Procesando: 13 - SesioÌn trabajo ingresos por moÌdulo-20240718_110628.mp4\n",
            "Actualizado en Google Sheets: 13 - SesioÌn trabajo ingresos por moÌdulo-20240718_110628.mp4\n",
            "\n",
            "Proceso completado. Hoja de cÃ¡lculo disponible en: https://docs.google.com/spreadsheets/d/18esoAyRzemkA3GLVTDV6k45U5KqQzkrULYt3sE99KiQ\n"
          ]
        }
      ],
      "source": [
        "#@title ConfiguraciÃ³n\n",
        "import os\n",
        "import time\n",
        "import ffmpeg\n",
        "import pandas as pd\n",
        "from whisper import load_model\n",
        "\n",
        "# Diccionario de configuraciÃ³n\n",
        "folder_path = r\"/content/drive/Shareddrives/AREA TIC COMPARTIDO USUARIOS EXTERNOS/ERP v6.0 - PROYECTO G-F (AYESA)/50 - BC/10 - DAF/Videos Sesiones DAF/\" #@param {type:\"string\"}\n",
        "model_size = \"medium\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
        "sheet_id = \"18esoAyRzemkA3GLVTDV6k45U5KqQzkrULYt3sE99KiQ\" # o None\n",
        "param = {\n",
        "    \"folder_path\": folder_path,\n",
        "    \"model_size\": model_size,\n",
        "    \"sheet_id\": sheet_id,  # ID de la hoja de Google Sheets,\n",
        "    \"verbose\": True  # Activar detalles adicionales\n",
        "}\n",
        "\n",
        "\n",
        "# Ejecutar el proceso orquestado\n",
        "orchestrate_transcription_to_GSpread(param)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title video_whisper_transcribe_to()\n",
        "def video_whisper_transcribe_to(params: dict) -> None:\n",
        "    \"\"\"\n",
        "    Orquesta la transcripciÃ³n de archivos de video en una carpeta utilizando el modelo Whisper y actualiza\n",
        "    una hoja de Google Sheets con los metadatos tÃ©cnicos y la transcripciÃ³n dividida en hasta 10 partes.\n",
        "\n",
        "    Args:\n",
        "        params (dict):\n",
        "            - folder_path (str): Ruta de la carpeta que contiene los videos. [OBLIGATORIO]\n",
        "            - model_size (str): TamaÃ±o del modelo Whisper (\"tiny\", \"base\", \"small\", \"medium\", \"large\"). Default: \"medium\".\n",
        "            - sheet_id (str | None): ID de la hoja de Google Sheets; si no se proporciona, se crearÃ¡ una nueva.\n",
        "            - verbose (bool): Indica si se muestran mensajes detallados. Default: False.\n",
        "            - ini_environment_identificated (str): Identificador del entorno. Opciones: \"LOCAL\", \"COLAB\", \"COLAB_ENTERPRISE\" o un project_id.\n",
        "            - json_keyfile_local (str): (Requerido en entorno LOCAL) Ruta al archivo JSON de credenciales.\n",
        "            - json_keyfile_colab (str): (Requerido en entornos COLAB) Ruta al archivo JSON de credenciales.\n",
        "            - json_keyfile_GCP_secret_id (str): (Requerido en entornos GCP) Secret ID del JSON de credenciales en Secret Manager.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        ValueError: Si faltan parÃ¡metros obligatorios o se produce un error durante la autenticaciÃ³n.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import json\n",
        "    import time\n",
        "    import ffmpeg\n",
        "    from datetime import datetime\n",
        "    from google.oauth2.service_account import Credentials\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ VALIDACIÃ“N DE PARÃMETROS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    if not params.get(\"folder_path\"):\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] Falta el parÃ¡metro 'folder_path' en params.\")\n",
        "    folder_path_str = params.get(\"folder_path\")\n",
        "    if not os.path.exists(folder_path_str):\n",
        "        raise ValueError(f\"[VALIDATION [ERROR âŒ]] La ruta indicada no existe: {folder_path_str}\")\n",
        "    model_size_str = params.get(\"model_size\", \"medium\")\n",
        "    verbose_bool = params.get(\"verbose\", False)\n",
        "\n",
        "    print(\"[START â–¶ï¸] Inicio del proceso de transcripciÃ³n de videos.\", flush=True)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AUTENTICACIÃ“N Y ACCESO A GOOGLE SHEETS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    env_str = params.get(\"ini_environment_identificated\")\n",
        "    if not env_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] Falta el parÃ¡metro 'ini_environment_identificated' en params.\")\n",
        "\n",
        "    if env_str == \"LOCAL\":\n",
        "        json_keyfile_local_str = params.get(\"json_keyfile_local\")\n",
        "        if not json_keyfile_local_str:\n",
        "            raise ValueError(\"[VALIDATION [ERROR âŒ]] En entorno LOCAL se debe proporcionar 'json_keyfile_local' en params.\")\n",
        "        print(\"[AUTHENTICATION [START â–¶ï¸]] Iniciando autenticaciÃ³n en entorno LOCAL mediante JSON de credenciales...\", flush=True)\n",
        "        try:\n",
        "            creds = Credentials.from_service_account_file(json_keyfile_local_str)\n",
        "            print(\"[AUTHENTICATION [SUCCESS âœ…]] AutenticaciÃ³n en entorno LOCAL completada.\", flush=True)\n",
        "        except Exception as error_local:\n",
        "            raise ValueError(f\"[AUTHENTICATION [ERROR âŒ]] Error durante la autenticaciÃ³n en entorno LOCAL: {error_local}\")\n",
        "    elif env_str == \"COLAB\":\n",
        "        json_keyfile_colab_str = params.get(\"json_keyfile_colab\")\n",
        "        if not json_keyfile_colab_str:\n",
        "            raise ValueError(\"[VALIDATION [ERROR âŒ]] En entornos COLAB se debe proporcionar 'json_keyfile_colab' en params.\")\n",
        "        print(\"[AUTHENTICATION [START â–¶ï¸]] Iniciando autenticaciÃ³n en entorno COLAB mediante JSON de credenciales...\", flush=True)\n",
        "        try:\n",
        "            creds = Credentials.from_service_account_file(json_keyfile_colab_str)\n",
        "            print(\"[AUTHENTICATION [SUCCESS âœ…]] AutenticaciÃ³n en entorno COLAB completada.\", flush=True)\n",
        "        except Exception as error_colab:\n",
        "            raise ValueError(f\"[AUTHENTICATION [ERROR âŒ]] Error durante la autenticaciÃ³n en COLAB: {error_colab}\")\n",
        "    elif env_str == \"COLAB_ENTERPRISE\" or (env_str not in [\"LOCAL\", \"COLAB\"]):\n",
        "        # Para COLAB_ENTERPRISE o cuando se pasa un project_id directamente\n",
        "        if env_str == \"COLAB_ENTERPRISE\":\n",
        "            project_id_env = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "            if not project_id_env:\n",
        "                raise ValueError(\"[VALIDATION [ERROR âŒ]] No se encontrÃ³ la variable de entorno 'GOOGLE_CLOUD_PROJECT'.\")\n",
        "        else:\n",
        "            project_id_env = env_str\n",
        "        json_keyfile_GCP_secret_id_str = params.get(\"json_keyfile_GCP_secret_id\")\n",
        "        if not json_keyfile_GCP_secret_id_str:\n",
        "            raise ValueError(\"[VALIDATION [ERROR âŒ]] En entornos GCP se debe proporcionar 'json_keyfile_GCP_secret_id' en params.\")\n",
        "        print(\"[AUTHENTICATION [START â–¶ï¸]] Iniciando autenticaciÃ³n en entorno GCP mediante Secret Manager...\", flush=True)\n",
        "        try:\n",
        "            from google.cloud import secretmanager\n",
        "            client_sm = secretmanager.SecretManagerServiceClient()\n",
        "            secret_name = f\"projects/{project_id_env}/secrets/{json_keyfile_GCP_secret_id_str}/versions/latest\"\n",
        "            response = client_sm.access_secret_version(name=secret_name)\n",
        "            secret_string = response.payload.data.decode(\"UTF-8\")\n",
        "            secret_info = json.loads(secret_string)\n",
        "            creds = Credentials.from_service_account_info(secret_info)\n",
        "            print(f\"[AUTHENTICATION [SUCCESS âœ…]] AutenticaciÃ³n en entorno GCP completada. (Secret Manager: {json_keyfile_GCP_secret_id_str})\", flush=True)\n",
        "        except Exception as error_gcp:\n",
        "            raise ValueError(f\"[AUTHENTICATION [ERROR âŒ]] Error durante la autenticaciÃ³n en GCP: {error_gcp}\")\n",
        "\n",
        "    try:\n",
        "        import gspread\n",
        "        gspread_client = gspread.authorize(creds)\n",
        "    except Exception as error_gs:\n",
        "        raise Exception(f\"[AUTHENTICATION [ERROR âŒ]] Error al autorizar Google Sheets: {error_gs}\")\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SUBFUNCIÃ“N: Obtener propiedades del video â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def _get_video_properties_dic(file_path_str: str) -> dict:\n",
        "        \"\"\"\n",
        "        Extrae las propiedades tÃ©cnicas del video.\n",
        "\n",
        "        Args:\n",
        "            file_path_str (str): Ruta completa del archivo de video.\n",
        "\n",
        "        Returns:\n",
        "            dict: Diccionario con metadatos tÃ©cnicos.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"[EXTRACTION [START â–¶ï¸]] Extrayendo metadatos de: {os.path.basename(file_path_str)}\", flush=True)\n",
        "            probe_dic = ffmpeg.probe(file_path_str)\n",
        "            video_stream_dic = next((stream for stream in probe_dic['streams'] if stream['codec_type'] == 'video'), None)\n",
        "            audio_stream_dic = next((stream for stream in probe_dic['streams'] if stream['codec_type'] == 'audio'), None)\n",
        "            properties_dic = {\n",
        "                \"file_name\": os.path.basename(file_path_str),\n",
        "                \"file_path\": file_path_str,\n",
        "                \"file_size_mb\": float(probe_dic['format']['size']) / (1024 * 1024),\n",
        "                \"duration_s\": float(probe_dic['format']['duration']),\n",
        "                \"video_codec\": video_stream_dic['codec_name'] if video_stream_dic else None,\n",
        "                \"audio_codec\": audio_stream_dic['codec_name'] if audio_stream_dic else None,\n",
        "                \"resolution\": f\"{video_stream_dic['width']}x{video_stream_dic['height']}\" if video_stream_dic else None,\n",
        "                \"audio_sample_rate\": int(audio_stream_dic['sample_rate']) if audio_stream_dic else None,\n",
        "            }\n",
        "            print(\"[EXTRACTION [SUCCESS âœ…]] Metadatos extraÃ­dos correctamente.\", flush=True)\n",
        "            return properties_dic\n",
        "        except Exception as error_meta:\n",
        "            print(f\"[EXTRACTION [ERROR âŒ]] Error al extraer metadatos: {error_meta}\", flush=True)\n",
        "            return {\n",
        "                \"file_name\": os.path.basename(file_path_str),\n",
        "                \"file_path\": file_path_str,\n",
        "                \"file_size_mb\": None,\n",
        "                \"duration_s\": None,\n",
        "                \"video_codec\": None,\n",
        "                \"audio_codec\": None,\n",
        "                \"resolution\": None,\n",
        "                \"audio_sample_rate\": None,\n",
        "                \"error\": str(error_meta)\n",
        "            }\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ APERTURA O CREACIÃ“N DE LA HOJA DE CÃLCULO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    sheet_id_str = params.get(\"sheet_id\")\n",
        "    try:\n",
        "        if sheet_id_str:\n",
        "            spreadsheet = gspread_client.open_by_key(sheet_id_str)\n",
        "            print(f\"[LOAD [INFO â„¹ï¸]] Hoja encontrada con ID: {sheet_id_str}\", flush=True)\n",
        "        else:\n",
        "            folder_name_str = os.path.basename(folder_path_str)\n",
        "            sheet_name_str = \"Transcripciones de Videos\"\n",
        "            spreadsheet = gspread_client.create(f\"{folder_name_str} - {sheet_name_str}\")\n",
        "            print(f\"[LOAD [INFO â„¹ï¸]] Hoja creada: {spreadsheet.title}\", flush=True)\n",
        "    except Exception as error_sheet:\n",
        "        raise Exception(f\"[LOAD [ERROR âŒ]] Error al acceder/crear la hoja de cÃ¡lculo: {error_sheet}\")\n",
        "\n",
        "    sheet = spreadsheet.sheet1\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIGURACIÃ“N DE CABECERAS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    HEADERS_list = [\n",
        "        \"file_name\", \"file_path\", \"file_size_mb\", \"duration_s\",\n",
        "        \"video_codec\", \"audio_codec\", \"resolution\", \"audio_sample_rate\",\n",
        "        \"transcription_date\",\n",
        "        \"transcription_part_1\", \"transcription_part_2\", \"transcription_part_3\",\n",
        "        \"transcription_part_4\", \"transcription_part_5\", \"transcription_part_6\",\n",
        "        \"transcription_part_7\", \"transcription_part_8\", \"transcription_part_9\",\n",
        "        \"transcription_part_10\"\n",
        "    ]\n",
        "    try:\n",
        "        existing_values_list = sheet.get_all_values()\n",
        "        if existing_values_list:\n",
        "            current_headers_list = existing_values_list[0]\n",
        "            if (\"file_name\" not in current_headers_list) or (len(current_headers_list) != len(HEADERS_list)):\n",
        "                sheet.clear()\n",
        "                sheet.update(\"A1\", [HEADERS_list])\n",
        "                print(\"[LOAD [INFO â„¹ï¸]] Cabecera actualizada en la hoja.\", flush=True)\n",
        "        else:\n",
        "            sheet.update(\"A1\", [HEADERS_list])\n",
        "            print(\"[LOAD [INFO â„¹ï¸]] Cabecera inicializada en la hoja.\", flush=True)\n",
        "    except Exception as error_headers:\n",
        "        print(f\"[LOAD [ERROR âŒ]] Error al configurar la cabecera: {error_headers}\", flush=True)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LECTURA DE REGISTROS EXISTENTES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    all_rows_list = sheet.get_all_records()\n",
        "    processed_files_dic = {\n",
        "        row.get(\"file_name\"): row.get(\"transcription_date\", \"N/A\")\n",
        "        for row in all_rows_list if row.get(\"file_name\") is not None\n",
        "    }\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LISTADO DE ARCHIVOS DE VIDEO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    video_files_list = [\n",
        "        file_name for file_name in os.listdir(folder_path_str)\n",
        "        if file_name.lower().endswith((\".mp4\", \".mkv\", \".avi\", \".mov\"))\n",
        "    ]\n",
        "    print(f\"[EXTRACTION [INFO â„¹ï¸]] Se encontraron {len(video_files_list)} archivos de video.\", flush=True)\n",
        "\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        status_data_list = []\n",
        "        for video_file_str in video_files_list:\n",
        "            status_str = \"Transcrito\" if video_file_str in processed_files_dic else \"No transcrito\"\n",
        "            date_str = processed_files_dic.get(video_file_str, \"N/A\")\n",
        "            status_data_list.append({\"file_name\": video_file_str, \"status\": status_str, \"transcription_date\": date_str})\n",
        "        status_df = pd.DataFrame(status_data_list)\n",
        "        print(\"\\n[METRICS [INFO â„¹ï¸]] Estado de los vÃ­deos:\", flush=True)\n",
        "        display(status_df)\n",
        "    except Exception as error_df:\n",
        "        print(f\"[METRICS [WARNING âš ï¸]] No se pudo mostrar el DataFrame de estado: {error_df}\", flush=True)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CARGA DEL MODELO WHISPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    try:\n",
        "        print(f\"[LOAD [START â–¶ï¸]] Cargando modelo Whisper '{model_size_str}'...\", flush=True)\n",
        "        from whisper import load_model\n",
        "        model = load_model(model_size_str)\n",
        "        print(f\"[LOAD [SUCCESS âœ…]] Modelo '{model_size_str}' cargado correctamente.\", flush=True)\n",
        "    except Exception as error_model:\n",
        "        raise Exception(f\"[LOAD [ERROR âŒ]] Error al cargar el modelo Whisper: {error_model}\")\n",
        "\n",
        "    max_chars_int = 50000  # MÃ¡ximo de caracteres por bloque\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PROCESAMIENTO DE CADA VIDEO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    for video_file_str in video_files_list:\n",
        "        if video_file_str in processed_files_dic:\n",
        "            if verbose_bool:\n",
        "                print(f\"[TRANSFORMATION [INFO â„¹ï¸]] Saltando archivo ya procesado: {video_file_str}\", flush=True)\n",
        "            continue\n",
        "\n",
        "        video_path_str = os.path.join(folder_path_str, video_file_str)\n",
        "        properties_dic = _get_video_properties_dic(video_path_str)\n",
        "\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TRANSCRIPCIÃ“N DEL VIDEO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        transcription_str = \"\"\n",
        "        try:\n",
        "            print(f\"[TRANSFORMATION [START â–¶ï¸]] Transcribiendo: {video_file_str}\", flush=True)\n",
        "            result_dic = model.transcribe(video_path_str, language='es')\n",
        "            transcription_str = result_dic.get(\"text\", \"\")\n",
        "            print(f\"[TRANSFORMATION [SUCCESS âœ…]] TranscripciÃ³n completada: {video_file_str}\", flush=True)\n",
        "        except Exception as error_trans:\n",
        "            print(f\"[TRANSFORMATION [ERROR âŒ]] Error transcribiendo {video_file_str}: {error_trans}\", flush=True)\n",
        "            transcription_str = \"\"\n",
        "\n",
        "        # Troceo de la transcripciÃ³n en bloques de 50k caracteres, limitado a 10 partes\n",
        "        transcription_parts_list = [\n",
        "            transcription_str[i : i + max_chars_int]\n",
        "            for i in range(0, len(transcription_str), max_chars_int)\n",
        "        ]\n",
        "        if len(transcription_parts_list) > 10:\n",
        "            sobrante_str = \"\".join(transcription_parts_list[10:])\n",
        "            transcription_parts_list[9] += sobrante_str\n",
        "            transcription_parts_list = transcription_parts_list[:10]\n",
        "        transcription_parts_list += [\"\"] * (10 - len(transcription_parts_list))\n",
        "\n",
        "        # ConstrucciÃ³n de la fila para la hoja de cÃ¡lculo\n",
        "        row_values_list = [\n",
        "            properties_dic.get(\"file_name\"),\n",
        "            properties_dic.get(\"file_path\"),\n",
        "            properties_dic.get(\"file_size_mb\"),\n",
        "            properties_dic.get(\"duration_s\"),\n",
        "            properties_dic.get(\"video_codec\"),\n",
        "            properties_dic.get(\"audio_codec\"),\n",
        "            properties_dic.get(\"resolution\"),\n",
        "            properties_dic.get(\"audio_sample_rate\"),\n",
        "            datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        ] + transcription_parts_list\n",
        "\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ACTUALIZACIÃ“N EN GOOGLE SHEETS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        reintentos_int = 3\n",
        "        for intento_int in range(reintentos_int):\n",
        "            try:\n",
        "                sheet.append_row(row_values_list, value_input_option=\"USER_ENTERED\")\n",
        "                if verbose_bool:\n",
        "                    print(f\"[LOAD [SUCCESS âœ…]] Actualizado en Google Sheets: {video_file_str}\", flush=True)\n",
        "                break\n",
        "            except Exception as error_append:\n",
        "                if intento_int < reintentos_int - 1:\n",
        "                    print(f\"[LOAD [WARNING âš ï¸]] Error al actualizar Google Sheets. Reintentando ({intento_int + 1}/{reintentos_int})...\", flush=True)\n",
        "                    time.sleep(5)\n",
        "                else:\n",
        "                    print(f\"[LOAD [ERROR âŒ]] Error persistente al actualizar Google Sheets: {error_append}\", flush=True)\n",
        "\n",
        "    print(f\"\\n[END [FINISHED âœ…]] Proceso completado. Hoja de cÃ¡lculo disponible en: {spreadsheet.url}\", flush=True)\n"
      ],
      "metadata": {
        "id": "vi0G1btEOo6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title TRANSCRIBE A SPREADSHEET\n",
        "params_colab = {\n",
        "    \"folder_path\": \"/content/drive/Shareddrives/AREA ACADEMICO/MOCADI/ViÌdeo Correcciones  /AnimacioÌn de Personajes 3D - Aca 1 - L06/NIVEL BAJO\",\n",
        "    \"model_size\": \"small\",\n",
        "    \"sheet_id\": \"1kr0WWfXQmiluErKkA0SUP7e9IYXqhKGTznazvsdfRbA\",                         # ID de la hoja de Google\n",
        "    \"verbose\": True,\n",
        "\n",
        "    \"ini_environment_identificated\": ini_environment_identificated,\n",
        "    \"json_keyfile_local\": GCP_json_keyfile_local,\n",
        "    \"json_keyfile_colab\": GCP_json_keyfile_colab,\n",
        "    \"json_keyfile_GCP_secret_id\": GCP_json_keyfile_GCP_secret_id,\n",
        "}\n",
        "\n",
        "video_whisper_transcribe_to(params_colab)"
      ],
      "metadata": {
        "id": "TNuwx8lqPm13",
        "outputId": "1409d1ea-1aaa-4836-868e-6434fa50517c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[START â–¶ï¸] Inicio del proceso de transcripciÃ³n de videos.\n",
            "[AUTHENTICATION [START â–¶ï¸]] Iniciando autenticaciÃ³n en entorno COLAB mediante JSON de credenciales...\n",
            "[AUTHENTICATION [SUCCESS âœ…]] AutenticaciÃ³n en entorno COLAB completada.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "[LOAD [ERROR âŒ]] Error al acceder/crear la hoja de cÃ¡lculo: ('invalid_scope: Invalid OAuth scope or ID token audience provided.', {'error': 'invalid_scope', 'error_description': 'Invalid OAuth scope or ID token audience provided.'})",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRefreshError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-68c017b6f596>\u001b[0m in \u001b[0;36mvideo_whisper_transcribe_to\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msheet_id_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mspreadsheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgspread_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_by_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet_id_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LOAD [INFO â„¹ï¸]] Hoja encontrada con ID: {sheet_id_str}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/client.py\u001b[0m in \u001b[0;36mopen_by_key\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mspreadsheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpreadsheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAPIError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/spreadsheet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, http_client, properties)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_sheet_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_properties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"properties\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/spreadsheet.py\u001b[0m in \u001b[0;36mfetch_sheet_metadata\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_sheet_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/http_client.py\u001b[0m in \u001b[0;36mfetch_sheet_metadata\u001b[0;34m(self, id, params)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, params, data, json, files, headers)\u001b[0m\n\u001b[1;32m    113\u001b[0m     ) -> Response:\n\u001b[0;32m--> 114\u001b[0;31m         response = self.session.request(\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0mremaining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/credentials.py\u001b[0m in \u001b[0;36mbefore_request\u001b[0;34m(self, request, method, url, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/credentials.py\u001b[0m in \u001b[0;36m_blocking_refresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/service_account.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0massertion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_authorization_grant_assertion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             access_token, expiry, _ = _client.jwt_grant(\n\u001b[0m\u001b[1;32m    449\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massertion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36mjwt_grant\u001b[0;34m(request, token_uri, assertion, can_retry)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     response_data = _token_endpoint_request(\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36m_token_endpoint_request\u001b[0;34m(request, token_uri, body, access_token, use_json, can_retry, headers, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse_status_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0m_handle_error_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretryable_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36m_handle_error_response\u001b[0;34m(response_data, retryable_error)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     raise exceptions.RefreshError(\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0merror_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretryable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretryable_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRefreshError\u001b[0m: ('invalid_scope: Invalid OAuth scope or ID token audience provided.', {'error': 'invalid_scope', 'error_description': 'Invalid OAuth scope or ID token audience provided.'})",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4b89dc466af2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mvideo_whisper_transcribe_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_colab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-68c017b6f596>\u001b[0m in \u001b[0;36mvideo_whisper_transcribe_to\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LOAD [INFO â„¹ï¸]] Hoja creada: {spreadsheet.title}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_sheet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LOAD [ERROR âŒ]] Error al acceder/crear la hoja de cÃ¡lculo: {error_sheet}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspreadsheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: [LOAD [ERROR âŒ]] Error al acceder/crear la hoja de cÃ¡lculo: ('invalid_scope: Invalid OAuth scope or ID token audience provided.', {'error': 'invalid_scope', 'error_description': 'Invalid OAuth scope or ID token audience provided.'})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title scrap_videofiles_local_dir_to_gspread()\n",
        "def scrap_videofiles_local_dir_to_gspread(params: dict) -> None:\n",
        "    \"\"\"\n",
        "    Busca archivos de video en una carpeta, ya sea en un sistema de archivos local o en Google Drive,\n",
        "    extrae sus propiedades tÃ©cnicas y envÃ­a los resultados a una hoja de Google Sheets.\n",
        "\n",
        "    La estrategia de bÃºsqueda se selecciona segÃºn el valor de 'ini_environment_identificated' y la existencia\n",
        "    de la ruta en el sistema de archivos. Si la ruta existe localmente, se realiza un escaneo con os.walk;\n",
        "    de lo contrario, se asume que se trata de una ruta de Google Drive y se utiliza la API de Drive para listar archivos.\n",
        "\n",
        "    Args:\n",
        "        params (dict):\n",
        "            - video_files_root_path (str): Ruta del directorio raÃ­z o URL del folder de Google Drive.\n",
        "            - video_files_target_search_folder (list): Lista de subcarpetas de interÃ©s dentro del directorio raÃ­z.\n",
        "            - video_files_target_search_extension (list): Lista de extensiones de archivo a buscar (ej.: [\".mp4\"]).\n",
        "            - ini_environment_identificated (str): Identificador del entorno. Ej.: \"LOCAL\", \"COLAB\", \"COLAB_ENTERPRISE\", etc.\n",
        "            - json_keyfile_local (str): Ruta al archivo JSON de credenciales para entornos LOCAL.\n",
        "            - json_keyfile_colab (str): Ruta al archivo JSON de credenciales para entornos COLAB.\n",
        "            - json_keyfile_GCP_secret_id (str): Secret ID del JSON de credenciales en Secret Manager (para entornos GCP).\n",
        "            - destination_files_path_table_spreadsheet_url (str): URL de la hoja de Google Sheets destino.\n",
        "            - destination_files_path_table_spreadsheet_worksheet (str): Nombre de la pestaÃ±a en la hoja destino.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        ValueError: Si falta algÃºn parÃ¡metro obligatorio o no se encuentran archivos.\n",
        "        Exception: Si ocurre un error al interactuar con Google Sheets.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import re\n",
        "    import subprocess\n",
        "    import json\n",
        "    import pandas as pd\n",
        "    from datetime import datetime\n",
        "    from time import time\n",
        "    from dpm_google import gspread_initialize_client, gspread_df_to_sheet\n",
        "    from googleapiclient.discovery import build  # Para Drive API\n",
        "\n",
        "    print(\"\\n[START â–¶ï¸] Inicio del proceso de scrap de videos a Google Sheets.\\n\", flush=True)\n",
        "    start_time_float = time()\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ VALIDACIÃ“N DE PARÃMETROS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    video_files_root_path_str = params.get('video_files_root_path')\n",
        "    target_folders_list = params.get('video_files_target_search_folder', [])\n",
        "    file_exts_list = params.get('video_files_target_search_extension', [])\n",
        "    ini_env_str = params.get(\"ini_environment_identificated\")\n",
        "    json_keyfile_local_str = params.get(\"json_keyfile_local\")\n",
        "    json_keyfile_colab_str = params.get(\"json_keyfile_colab\")\n",
        "    json_keyfile_GCP_secret_id_str = params.get(\"json_keyfile_GCP_secret_id\")\n",
        "    spreadsheet_url_str = params.get('destination_files_path_table_spreadsheet_url')\n",
        "    worksheet_name_str = params.get('destination_files_path_table_spreadsheet_worksheet')\n",
        "\n",
        "    if not video_files_root_path_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] El parÃ¡metro 'video_files_root_path' es obligatorio.\")\n",
        "    if not file_exts_list:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] El parÃ¡metro 'video_files_target_search_extension' es obligatorio y debe contener al menos una extensiÃ³n.\")\n",
        "    if not ini_env_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] El parÃ¡metro 'ini_environment_identificated' es obligatorio.\")\n",
        "    if not json_keyfile_local_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] El parÃ¡metro 'json_keyfile_local' es obligatorio.\")\n",
        "    if not json_keyfile_colab_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] El parÃ¡metro 'json_keyfile_colab' es obligatorio.\")\n",
        "    if not json_keyfile_GCP_secret_id_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] El parÃ¡metro 'json_keyfile_GCP_secret_id' es obligatorio.\")\n",
        "    if not spreadsheet_url_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] El parÃ¡metro 'destination_files_path_table_spreadsheet_url' es obligatorio.\")\n",
        "    if not worksheet_name_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] El parÃ¡metro 'destination_files_path_table_spreadsheet_worksheet' es obligatorio.\")\n",
        "\n",
        "    print(\"[INFO â„¹ï¸] ParÃ¡metros validados correctamente.\\n\", flush=True)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SELECCIÃ“N DE MÃ‰TODO DE BÃšSQUEDA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # Si la ruta existe localmente, se utiliza os.walk. De lo contrario, se asume que es una ruta de Google Drive.\n",
        "    def _find_files_in_folders(root_str: str, folders_list: list, exts_list: list) -> pd.DataFrame:\n",
        "        results_list = []\n",
        "        for dirpath, dirnames, filenames in os.walk(root_str):\n",
        "            current_folder_str = os.path.basename(dirpath)\n",
        "            if folders_list and current_folder_str not in folders_list:\n",
        "                continue\n",
        "            for file_str in filenames:\n",
        "                _, file_ext_str = os.path.splitext(file_str)\n",
        "                if file_ext_str.lower() in [ext.lower() for ext in exts_list]:\n",
        "                    file_path_str = os.path.join(dirpath, file_str)\n",
        "                    results_list.append({\n",
        "                        \"video_file_path\": file_path_str,\n",
        "                        \"video_file_name\": file_str\n",
        "                    })\n",
        "                    print(f\"[INFO â„¹ï¸] â¤ Archivo encontrado: {file_str} (Ruta: {file_path_str})\", flush=True)\n",
        "        if not results_list:\n",
        "            print(\"[WARNING âš ï¸] No se encontraron archivos que coincidan con los criterios especificados.\\n\", flush=True)\n",
        "            return pd.DataFrame()\n",
        "        return pd.DataFrame(results_list)\n",
        "\n",
        "    def _find_files_in_drive(folder_url: str, exts_list: list, creds) -> pd.DataFrame:\n",
        "        # Se asume que folder_url es la URL de la carpeta en Drive; se extrae el ID.\n",
        "        m = re.search(r'/d/([a-zA-Z0-9_-]+)', folder_url)\n",
        "        folder_id = m.group(1) if m else folder_url\n",
        "        drive_service = build('drive', 'v3', credentials=creds)\n",
        "        query = f\"'{folder_id}' in parents and trashed = false\"\n",
        "        results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "        files = results.get('files', [])\n",
        "        results_list = []\n",
        "        for f in files:\n",
        "            name = f.get('name', '')\n",
        "            _, file_ext_str = os.path.splitext(name)\n",
        "            if file_ext_str.lower() in [ext.lower() for ext in exts_list]:\n",
        "                results_list.append({\n",
        "                    \"video_file_path\": f.get('id'),  # Para Drive se usa el ID del archivo\n",
        "                    \"video_file_name\": name\n",
        "                })\n",
        "                print(f\"[INFO â„¹ï¸] â¤ Archivo encontrado: {name} (Drive ID: {f.get('id')})\", flush=True)\n",
        "        if not results_list:\n",
        "            print(\"[WARNING âš ï¸] No se encontraron archivos en Drive que coincidan con los criterios.\", flush=True)\n",
        "            return pd.DataFrame()\n",
        "        return pd.DataFrame(results_list)\n",
        "\n",
        "    # Se requiere autenticar previamente para usar tanto Sheets como Drive.\n",
        "    # AquÃ­ reutilizamos el cliente de Sheets (gspread) que se inicializarÃ¡ mÃ¡s adelante para obtener las credenciales.\n",
        "    # Para el listado en Drive, se crearÃ¡n a partir del mismo mÃ©todo de autenticaciÃ³n en gspread_initialize_client.\n",
        "    drive_scan_required = not os.path.exists(video_files_root_path_str)\n",
        "    if drive_scan_required:\n",
        "        print(f\"[INFO â„¹ï¸] La ruta '{video_files_root_path_str}' no se encontrÃ³ localmente; se asume que es una ruta de Google Drive.\\n\", flush=True)\n",
        "    else:\n",
        "        print(f\"[INFO â„¹ï¸] Se encontrÃ³ la ruta local '{video_files_root_path_str}'. Usando bÃºsqueda local.\\n\", flush=True)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AUTENTICACIÃ“N PARA GOOGLE SHEETS Y DRIVE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # Se utiliza la estrategia de autenticaciÃ³n definida por las nuevas keys.\n",
        "    client = gspread_initialize_client({\n",
        "        \"ini_environment_identificated\": ini_env_str,\n",
        "        \"json_keyfile_local\": json_keyfile_local_str,\n",
        "        \"json_keyfile_colab\": json_keyfile_colab_str,\n",
        "        \"json_keyfile_GCP_secret_id\": json_keyfile_GCP_secret_id_str\n",
        "    })\n",
        "    if not client:\n",
        "        raise Exception(\"[AUTHENTICATION [ERROR âŒ]] No se pudo autenticar con Google Sheets.\")\n",
        "    print(\"[SUCCESS âœ…] Cliente autenticado correctamente.\\n\", flush=True)\n",
        "    # Extraer las credenciales del cliente para usarlas con la API de Drive.\n",
        "    creds = client.auth.token  if hasattr(client, \"auth\") else None\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ OBTENCIÃ“N DE ARCHIVOS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    if drive_scan_required:\n",
        "        df_paths = _find_files_in_drive(video_files_root_path_str, file_exts_list, client.auth.credentials)\n",
        "    else:\n",
        "        df_paths = _find_files_in_folders(video_files_root_path_str, target_folders_list, file_exts_list)\n",
        "\n",
        "    if df_paths.empty:\n",
        "        raise ValueError(\"[VALIDATION [ERROR âŒ]] No se encontraron archivos que coincidan con los criterios especificados.\")\n",
        "    print(f\"[INFO â„¹ï¸] Total de archivos encontrados: {len(df_paths)}\\n\", flush=True)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ EXTRACCIÃ“N DE PROPIEDADES DE VIDEO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def _extract_video_properties(file_path_str: str) -> dict:\n",
        "        try:\n",
        "            # En Drive, dado que solo tenemos el ID, se requerirÃ­a descargar el archivo; aquÃ­ se asume que\n",
        "            # los archivos locales se procesan con ffprobe. Para Drive, se deberÃ­a implementar la descarga previa.\n",
        "            if drive_scan_required:\n",
        "                raise NotImplementedError(\"La extracciÃ³n de propiedades para archivos en Drive requiere descarga previa.\")\n",
        "            file_size_int = os.path.getsize(file_path_str) // (1024 * 1024)\n",
        "            result = subprocess.run([\n",
        "                'ffprobe', '-v', 'error', '-print_format', 'json', '-show_streams', '-show_format', file_path_str\n",
        "            ], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "            info_dic = json.loads(result.stdout)\n",
        "            video_codec_str = audio_codec_str = None\n",
        "            video_bitrate_int = audio_bitrate_int = 0\n",
        "            video_width_int = video_height_int = None\n",
        "            video_fps_float = None\n",
        "            audio_channels_int = audio_sample_rate_int = None\n",
        "            duration_float = 0.0\n",
        "\n",
        "            if 'streams' in info_dic:\n",
        "                for stream in info_dic['streams']:\n",
        "                    if stream.get('codec_type') == 'video':\n",
        "                        video_codec_str = stream.get('codec_name')\n",
        "                        video_bitrate_int = int(stream.get('bit_rate', 0)) // 1000\n",
        "                        video_width_int = stream.get('width')\n",
        "                        video_height_int = stream.get('height')\n",
        "                        if 'r_frame_rate' in stream:\n",
        "                            num_int, den_int = map(int, stream['r_frame_rate'].split('/'))\n",
        "                            video_fps_float = num_int / den_int if den_int != 0 else None\n",
        "                    elif stream.get('codec_type') == 'audio':\n",
        "                        audio_codec_str = stream.get('codec_name')\n",
        "                        audio_bitrate_int = int(stream.get('bit_rate', 0)) // 1000\n",
        "                        audio_channels_int = stream.get('channels')\n",
        "                        audio_sample_rate_int = int(stream.get('sample_rate', 0))\n",
        "            if 'format' in info_dic:\n",
        "                duration_float = float(info_dic['format'].get('duration', 0))\n",
        "                duration_ms_int = int(duration_float * 1000)\n",
        "                duration_hms_str = \"{:02d}:{:02d}:{:02d}\".format(\n",
        "                    int(duration_float) // 3600, (int(duration_float) % 3600) // 60, int(duration_float) % 60\n",
        "                )\n",
        "            else:\n",
        "                duration_ms_int = 0\n",
        "                duration_hms_str = \"00:00:00\"\n",
        "\n",
        "            return {\n",
        "                \"file_name\": os.path.basename(file_path_str),\n",
        "                \"file_path\": file_path_str,\n",
        "                \"file_creation_date\": datetime.fromtimestamp(os.path.getctime(file_path_str)).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"file_last_modified_date\": datetime.fromtimestamp(os.path.getmtime(file_path_str)).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"file_scrap_date\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"file_size_mb\": file_size_int,\n",
        "                \"duration_hms\": duration_hms_str,\n",
        "                \"duration_ms\": duration_ms_int,\n",
        "                \"video_codec\": video_codec_str,\n",
        "                \"video_bitrate_kbps\": video_bitrate_int,\n",
        "                \"video_fps\": video_fps_float,\n",
        "                \"video_resolution\": f\"{video_width_int}x{video_height_int}\" if video_width_int and video_height_int else None,\n",
        "                \"audio_codec\": audio_codec_str,\n",
        "                \"audio_bitrate_kbps\": audio_bitrate_int,\n",
        "                \"audio_channels\": audio_channels_int,\n",
        "                \"audio_sample_rate_hz\": audio_sample_rate_int,\n",
        "            }\n",
        "        except Exception as error_prop:\n",
        "            print(f\"[EXTRACTION [ERROR âŒ]] Error al obtener propiedades del video: {error_prop}\", flush=True)\n",
        "            return {\n",
        "                \"file_name\": os.path.basename(file_path_str),\n",
        "                \"file_path\": file_path_str,\n",
        "                \"file_creation_date\": \"unknown\",\n",
        "                \"file_last_modified_date\": \"unknown\",\n",
        "                \"file_scrap_date\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"file_size_mb\": 0,\n",
        "                \"duration_hms\": \"00:00:00\",\n",
        "                \"duration_ms\": 0,\n",
        "                \"video_codec\": \"unknown\",\n",
        "                \"video_bitrate_kbps\": 0,\n",
        "                \"video_fps\": 0,\n",
        "                \"video_resolution\": \"unknown\",\n",
        "                \"audio_codec\": \"unknown\",\n",
        "                \"audio_bitrate_kbps\": 0,\n",
        "                \"audio_channels\": 0,\n",
        "                \"audio_sample_rate_hz\": 0,\n",
        "            }\n",
        "\n",
        "    print(\"[START â–¶ï¸] Extrayendo propiedades de los videos...\\n\", flush=True)\n",
        "    df_video_props = df_paths['video_file_path'].apply(_extract_video_properties).apply(pd.Series)\n",
        "    print(\"[SUCCESS âœ…] Propiedades extraÃ­das correctamente.\\n\", flush=True)\n",
        "\n",
        "    df_paths_properties = df_video_props[[\n",
        "        \"file_name\",\n",
        "        \"file_path\",\n",
        "        \"file_creation_date\",\n",
        "        \"file_last_modified_date\",\n",
        "        \"file_scrap_date\",\n",
        "        \"file_size_mb\",\n",
        "        \"duration_hms\",\n",
        "        \"duration_ms\",\n",
        "        \"video_codec\",\n",
        "        \"video_bitrate_kbps\",\n",
        "        \"video_fps\",\n",
        "        \"video_resolution\",\n",
        "        \"audio_codec\",\n",
        "        \"audio_bitrate_kbps\",\n",
        "        \"audio_channels\",\n",
        "        \"audio_sample_rate_hz\",\n",
        "    ]]\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RESPALDO LOCAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    backup_csv_path_str = \"video_files_backup.csv\"\n",
        "    df_paths_properties.to_csv(backup_csv_path_str, index=False)\n",
        "    print(f\"[INFO â„¹ï¸] Datos respaldados localmente en: {backup_csv_path_str}\\n\", flush=True)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ESTADÃSTICAS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    total_videos_int = len(df_paths_properties)\n",
        "    print(f\"[METRICS [INFO â„¹ï¸]] NÃºmero total de videos procesados: {total_videos_int}\", flush=True)\n",
        "    process_duration_float = time() - start_time_float\n",
        "    print(f\"[METRICS [INFO â„¹ï¸]] DuraciÃ³n total del proceso: {process_duration_float:.2f} segundos\\n\", flush=True)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ENVÃO A GOOGLE SHEETS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(\"[START â–¶ï¸] Enviando datos a Google Sheets...\\n\", flush=True)\n",
        "    gspread_df_to_sheet({\n",
        "        'client': client,\n",
        "        'spreadsheet_url': spreadsheet_url_str,\n",
        "        'worksheet_name': worksheet_name_str,\n",
        "        'df': df_paths_properties,\n",
        "        'row_filter_list': list(range(len(df_paths_properties))),\n",
        "        'col_filter_list': '',\n",
        "        'include_header': True\n",
        "    })\n",
        "    print(\"[SUCCESS âœ…] Datos enviados exitosamente.\\n\", flush=True)\n",
        "\n",
        "    os.remove(backup_csv_path_str)\n",
        "    print(f\"[INFO â„¹ï¸] Respaldo local eliminado: {backup_csv_path_str}\\n\", flush=True)\n",
        "    print(\"[END [FINISHED âœ…]] Proceso completado.\\n\", flush=True)\n"
      ],
      "metadata": {
        "id": "mCGdqT0nY9w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title PATH FILES A SPREADSHEET\n",
        "# Ejemplo de uso para scrap_videofiles_local_dir_to_gspread()\n",
        "\n",
        "params_example = {\n",
        "    \"video_files_root_path\": \"/content/drive/MyDrive/Videos\",\n",
        "       # Puede ser una ruta local (ej.: \"C:/videos\") o una URL de carpeta de Google Drive (ej.: \"https://drive.google.com/drive/folders/ID_FOLDER\")\n",
        "    \"video_files_target_search_folder\": [\"Subcarpeta1\", \"Subcarpeta2\"],  # Subcarpetas de interÃ©s (opcional)\n",
        "    \"video_files_target_search_extension\": [\".mp4\", \".mkv\"],            # Extensiones de video a buscar\n",
        "\n",
        "    \"ini_environment_identificated\": ini_environment_identificated,\n",
        "       # Ej.: \"LOCAL\" para escanear localmente o \"DRIVE\" (u otro valor distinto a \"LOCAL\") para escanear Google Drive\n",
        "    \"json_keyfile_local\": GCP_json_keyfile_local,                        # Ruta al JSON de credenciales para LOCAL\n",
        "    \"json_keyfile_colab\": GCP_json_keyfile_colab,                        # Ruta al JSON de credenciales para COLAB\n",
        "    \"json_keyfile_GCP_secret_id\": GCP_json_keyfile_GCP_secret_id,          # Secret ID para autenticaciÃ³n en GCP\n",
        "\n",
        "    \"destination_files_path_table_spreadsheet_url\": \"https://docs.google.com/spreadsheets/d/ID_HOJA_DESTINO\",\n",
        "    \"destination_files_path_table_spreadsheet_worksheet\": \"Videos\"       # Nombre de la pestaÃ±a destino\n",
        "}\n",
        "\n",
        "scrap_videofiles_local_dir_to_gspread(params_example)\n"
      ],
      "metadata": {
        "id": "VwLiEDRzZBgr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnJRTd3dG+aGsCNKPPgNS1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}