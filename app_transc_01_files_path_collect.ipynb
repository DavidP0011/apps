{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidP0011/apps/blob/main/app_transc_01_files_path_collect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INICIALIZACIÓN"
      ],
      "metadata": {
        "id": "nxXmQcqu9E_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title dpm_ini_utils.py (GitHub)\n",
        "\n",
        "import os         # Para operaciones del sistema y manejo de rutas.\n",
        "import sys        # Para interactuar con el sistema, en particular con sys.path.\n",
        "import importlib  # Para realizar importaciones dinámicas.\n",
        "import tempfile   # Para crear archivos temporales.\n",
        "import requests   # Para realizar peticiones HTTP y descargar el módulo.\n",
        "\n",
        "# URL raw del módulo en GitHub (debe incluir las funciones ini_load_dpm_libs, ini_environment_identification e ini_google_drive_instalation)\n",
        "github_url = \"https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_ini_utils.py\"\n",
        "\n",
        "# Solicitar la descarga sin utilizar caché, para asegurar que se obtiene la versión actualizada.\n",
        "headers = {\"Cache-Control\": \"no-cache\", \"Pragma\": \"no-cache\"}\n",
        "response = requests.get(github_url, headers=headers)\n",
        "if response.status_code != 200:\n",
        "    raise Exception(f\"Error al descargar el módulo desde GitHub. Código: {response.status_code}\")\n",
        "\n",
        "# Guardar el contenido descargado en un archivo temporal.\n",
        "temp_dir = tempfile.gettempdir()\n",
        "module_path = os.path.join(temp_dir, \"dpm_ini_utils.py\")\n",
        "with open(module_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Agregar el directorio temporal a sys.path si aún no está incluido, para permitir la importación.\n",
        "if temp_dir not in sys.path:\n",
        "    sys.path.insert(0, temp_dir)\n",
        "\n",
        "# Invalidar cachés y eliminar versiones previas del módulo para forzar la recarga.\n",
        "importlib.invalidate_caches()\n",
        "module_name = \"dpm_ini_utils\"\n",
        "if module_name in sys.modules:\n",
        "    del sys.modules[module_name]\n",
        "\n",
        "# Importar y recargar el módulo.\n",
        "module = importlib.import_module(module_name)\n",
        "module = importlib.reload(module)\n",
        "\n",
        "# Intentar importar las funciones deseadas desde el módulo.\n",
        "ini_install_libraries = getattr(module, \"ini_install_libraries\", None)\n",
        "ini_load_dpm_libs = getattr(module, \"ini_load_dpm_libs\", None)\n",
        "ini_environment_identification = getattr(module, \"ini_environment_identification\", None)\n",
        "ini_google_drive_instalation = getattr(module, \"ini_google_drive_instalation\", None)\n",
        "\n",
        "# Verificar que las funciones se hayan importado correctamente.\n",
        "if ini_install_libraries is None:\n",
        "    print(\"La función ini_install_libraries no se encontró en el módulo.\")\n",
        "else:\n",
        "    print(\"Función ini_install_libraries cargada correctamente.\")\n",
        "\n",
        "if ini_load_dpm_libs is None:\n",
        "    print(\"La función ini_load_dpm_libs no se encontró en el módulo.\")\n",
        "else:\n",
        "    print(\"Función ini_load_dpm_libs cargada correctamente.\")\n",
        "\n",
        "if ini_environment_identification is None:\n",
        "    print(\"La función ini_environment_identification no se encontró en el módulo.\")\n",
        "else:\n",
        "    print(\"Función ini_environment_identification cargada correctamente.\")\n",
        "\n",
        "if ini_google_drive_instalation is None:\n",
        "    print(\"La función ini_google_drive_instalation no se encontró en el módulo.\")\n",
        "else:\n",
        "    print(\"Función ini_google_drive_instalation cargada correctamente.\")\n"
      ],
      "metadata": {
        "id": "EPbRzlCq9Clc",
        "outputId": "b468464a-692d-4b78-87a6-90e18956cfab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Función ini_install_libraries cargada correctamente.\n",
            "Función ini_load_dpm_libs cargada correctamente.\n",
            "Función ini_environment_identification cargada correctamente.\n",
            "Función ini_google_drive_instalation cargada correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title IDENTIFICACION DE ENTORNO, INSTALACIÓN GOOGLE DRIVE\n",
        "\n",
        "# Detectar el entorno de ejecución\n",
        "ini_environment_identificated = ini_environment_identification()\n",
        "print(f\"[INFO ℹ️] Entorno detectado: {ini_environment_identificated}\", flush=True)\n",
        "\n",
        "GCP_json_keyfile_local = r\"C:/api_keys/XXX.json\"\n",
        "GCP_json_keyfile_colab = \"/content/drive/MyDrive/ANIMUM DIRECCION/DIRECCION BI/NOTEBOOKS/api_keys/animum-dev-apps-google-colab.json\"\n",
        "GCP_json_keyfile_GCP_secret_id = \"notebook-vm\"\n",
        "\n",
        "# Montar Google Drive si entorno_identificado_str es Colab\n",
        "params = {\"entorno_identificado_str\": ini_environment_identificated}\n",
        "ini_google_drive_instalation(params)"
      ],
      "metadata": {
        "id": "1_UyYEYp9M2a",
        "outputId": "7861f2b5-c970-4663-bf3f-1221c3f5580b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO ℹ️] Entorno detectado: COLAB\n",
            "Mounted at /content/drive\n",
            "[INFO ℹ️] Google Drive montado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title INSTALACION DE LIBRERIAS\n",
        "from IPython import get_ipython\n",
        "import os\n",
        "packages = [\n",
        "    # Ejemplos originales:\n",
        "    {\n",
        "        \"name\": \"whisper\",\n",
        "        \"import_name\": \"whisper\",\n",
        "        # Instalación desde GitHub:\n",
        "        \"install_cmd\": \"pip install git+https://github.com/openai/whisper.git\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"ffmpeg-python\",\n",
        "        \"import_name\": \"ffmpeg\",\n",
        "        \"pip_name\": \"ffmpeg-python\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"FFmpeg\",  # Paquete del sistema\n",
        "        \"is_system\": True,\n",
        "        \"check_cmd\": \"ffmpeg -version\",\n",
        "        \"install_cmds\": [\n",
        "            \"apt-get update\",\n",
        "            \"apt-get install -y ffmpeg\",\n",
        "            \"ffmpeg -version\"\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    {\"name\": \"rapidfuzz\", \"import_name\": \"rapidfuzz\", \"pip_name\": \"rapidfuzz\"},\n",
        "    {\"name\": \"pycountry\", \"import_name\": \"pycountry\", \"pip_name\": \"pycountry\"},\n",
        "    {\"name\": \"phonenumbers\", \"import_name\": \"phonenumbers\", \"pip_name\": \"phonenumbers\"},\n",
        "    {\"name\": \"deep_translator\", \"import_name\": \"deep_translator\", \"pip_name\": \"deep_translator\"},\n",
        "    {\"name\": \"requests\", \"import_name\": \"requests\", \"pip_name\": \"requests\"},\n",
        "    {\"name\": \"beautifulsoup4\", \"import_name\": \"bs4\", \"pip_name\": \"beautifulsoup4\"},\n",
        "    {\"name\": \"googletrans\", \"import_name\": \"googletrans\", \"pip_name\": \"googletrans\", \"version\": \"4.0.0-rc1\"},\n",
        "]\n",
        "\n",
        "# Ejecuta la función para cada paquete\n",
        "for pkg in packages:\n",
        "    ini_install_libraries(pkg)\n"
      ],
      "metadata": {
        "id": "eQoX3eAX9SJY",
        "outputId": "a91373c3-dfd6-481d-fdbf-07edb48ad35d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[START ▶️] Verificando instalación de whisper...\n",
            "[INSTALLATION [INFO ℹ️]] whisper no está instalado. Procediendo con la instalación...\n",
            "[INSTALLATION [COMMAND ▶️]] Ejecutando comando personalizado: pip install git+https://github.com/openai/whisper.git\n",
            "[END [FINISHED ✅]] Proceso de instalación finalizado para whisper.\n",
            "\n",
            "\n",
            "[START ▶️] Verificando instalación de ffmpeg-python...\n",
            "[INSTALLATION [INFO ℹ️]] ffmpeg-python no está instalado. Procediendo con la instalación...\n",
            "[INSTALLATION [COMMAND ▶️]] Ejecutando: pip install --upgrade ffmpeg-python\n",
            "[END [FINISHED ✅]] Proceso de instalación finalizado para ffmpeg-python.\n",
            "\n",
            "\n",
            "[START ▶️] Verificando instalación de FFmpeg...\n",
            "[INSTALLATION [SUCCESS ✅]] FFmpeg ya está instalado.\n",
            "\n",
            "[START ▶️] Verificando instalación de rapidfuzz...\n",
            "[INSTALLATION [INFO ℹ️]] rapidfuzz no está instalado. Procediendo con la instalación...\n",
            "[INSTALLATION [COMMAND ▶️]] Ejecutando: pip install --upgrade rapidfuzz\n",
            "[END [FINISHED ✅]] Proceso de instalación finalizado para rapidfuzz.\n",
            "\n",
            "\n",
            "[START ▶️] Verificando instalación de pycountry...\n",
            "[INSTALLATION [INFO ℹ️]] pycountry no está instalado. Procediendo con la instalación...\n",
            "[INSTALLATION [COMMAND ▶️]] Ejecutando: pip install --upgrade pycountry\n",
            "[END [FINISHED ✅]] Proceso de instalación finalizado para pycountry.\n",
            "\n",
            "\n",
            "[START ▶️] Verificando instalación de phonenumbers...\n",
            "[INSTALLATION [INFO ℹ️]] phonenumbers no está instalado. Procediendo con la instalación...\n",
            "[INSTALLATION [COMMAND ▶️]] Ejecutando: pip install --upgrade phonenumbers\n",
            "[END [FINISHED ✅]] Proceso de instalación finalizado para phonenumbers.\n",
            "\n",
            "\n",
            "[START ▶️] Verificando instalación de deep_translator...\n",
            "[INSTALLATION [INFO ℹ️]] deep_translator no está instalado. Procediendo con la instalación...\n",
            "[INSTALLATION [COMMAND ▶️]] Ejecutando: pip install --upgrade deep_translator\n",
            "[END [FINISHED ✅]] Proceso de instalación finalizado para deep_translator.\n",
            "\n",
            "\n",
            "[START ▶️] Verificando instalación de requests...\n",
            "[INSTALLATION [SUCCESS ✅]] requests ya está instalado.\n",
            "[END [FINISHED ✅]] Proceso de instalación finalizado para requests.\n",
            "\n",
            "\n",
            "[START ▶️] Verificando instalación de beautifulsoup4...\n",
            "[INSTALLATION [SUCCESS ✅]] beautifulsoup4 ya está instalado.\n",
            "[END [FINISHED ✅]] Proceso de instalación finalizado para beautifulsoup4.\n",
            "\n",
            "\n",
            "[START ▶️] Verificando instalación de googletrans...\n",
            "[INSTALLATION [INFO ℹ️]] googletrans no está instalado. Procediendo con la instalación...\n",
            "[INSTALLATION [COMMAND ▶️]] Ejecutando: pip install --upgrade googletrans==4.0.0-rc1\n",
            "[END [FINISHED ✅]] Proceso de instalación finalizado para googletrans.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title IMPORTACIÓN DE LIBRERÍAS DPM\n",
        "import sys\n",
        "import os\n",
        "import importlib\n",
        "import datetime\n",
        "import inspect\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Configuración para importar librerías personalizadas\n",
        "config = [\n",
        "    {\n",
        "        \"module_host\": \"github\",\n",
        "        # Se utiliza la URL raw para obtener el contenido real del archivo\n",
        "        \"module_path\": \"https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_tables.py\",\n",
        "        \"selected_functions_list\": []\n",
        "    },\n",
        "    {\n",
        "        \"module_host\": \"github\",\n",
        "        # Se utiliza la URL raw para obtener el contenido real del archivo\n",
        "        \"module_path\": \"https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_GCP_utils.py\",\n",
        "        \"selected_functions_list\": []\n",
        "    },\n",
        "    {\n",
        "        \"module_host\": \"github\",\n",
        "        \"module_path\": \"https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_SQL.py\",\n",
        "        \"selected_functions_list\": []\n",
        "    }\n",
        "]\n",
        "\n",
        "# Cargar las librerías personalizadas\n",
        "ini_load_dpm_libs(config)\n"
      ],
      "metadata": {
        "id": "ExZnlgxzN3hT",
        "outputId": "b91e0048-f726-4fa6-b6cb-9ca2de6a91b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹🔹🔹 [START ▶️] Iniciando carga de módulo dpm_tables.py 🔹🔹🔹\n",
            "\n",
            "[EXTRACTION [START ▶️]] Descargando módulo desde GitHub: https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_tables.py\n",
            "[EXTRACTION [SUCCESS ✅]] Archivo descargado y guardado en: /tmp/dpm_tables.py\n",
            "[LOAD [START ▶️]] Importando módulo: dpm_tables\n",
            "[LOAD [SUCCESS ✅]] Módulo 'dpm_tables' importado correctamente.\n",
            "\n",
            "[METRICS [INFO 📊]] Informe de carga del módulo:\n",
            "  - Módulo: dpm_tables\n",
            "  - Ruta: /tmp/dpm_tables.py\n",
            "  - Fecha de última modificación (último commit en GitHub o mod. local): 2025-03-11 17:42:43+01:00\n",
            "  - Objetos importados:\n",
            "      • fields_name_format (function): Formatea nombres de campos de datos según configuraciones específicas.\n",
            "      • table_DF_to_various_targets (function): Escribe un DataFrame en distintos destinos (archivo local, Google Sheets, BigQuery o GCS)\n",
            "      • table_various_sources_to_DF (function): Extrae datos desde distintos orígenes (archivo, Google Sheets, BigQuery o GCS) y los convierte en un DataFrame.\n",
            "\n",
            "[END [FINISHED ✅]] Módulo 'dpm_tables' actualizado e importado en los builtins.\n",
            "\n",
            "\n",
            "🔹🔹🔹 [START ▶️] Iniciando carga de módulo dpm_GCP_utils.py 🔹🔹🔹\n",
            "\n",
            "[EXTRACTION [START ▶️]] Descargando módulo desde GitHub: https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_GCP_utils.py\n",
            "[EXTRACTION [SUCCESS ✅]] Archivo descargado y guardado en: /tmp/dpm_GCP_utils.py\n",
            "[LOAD [START ▶️]] Importando módulo: dpm_GCP_utils\n",
            "[LOAD [SUCCESS ✅]] Módulo 'dpm_GCP_utils' importado correctamente.\n",
            "\n",
            "[METRICS [INFO 📊]] Informe de carga del módulo:\n",
            "  - Módulo: dpm_GCP_utils\n",
            "  - Ruta: /tmp/dpm_GCP_utils.py\n",
            "  - Fecha de última modificación (último commit en GitHub o mod. local): 2025-03-11 17:29:30+01:00\n",
            "  - Objetos importados:\n",
            "      • GBQ_tables_schema_df (function): Retorna un DataFrame con la información de datasets, tablas y campos de un proyecto de BigQuery,\n",
            "      • GCS_tables_schema_df (function): Retorna un DataFrame con información detallada de:\n",
            "\n",
            "[END [FINISHED ✅]] Módulo 'dpm_GCP_utils' actualizado e importado en los builtins.\n",
            "\n",
            "\n",
            "🔹🔹🔹 [START ▶️] Iniciando carga de módulo dpm_SQL.py 🔹🔹🔹\n",
            "\n",
            "[EXTRACTION [START ▶️]] Descargando módulo desde GitHub: https://raw.githubusercontent.com/DavidP0011/utils/main/dpm_SQL.py\n",
            "[EXTRACTION [SUCCESS ✅]] Archivo descargado y guardado en: /tmp/dpm_SQL.py\n",
            "[LOAD [START ▶️]] Importando módulo: dpm_SQL\n",
            "[LOAD [SUCCESS ✅]] Módulo 'dpm_SQL' importado correctamente.\n",
            "\n",
            "[METRICS [INFO 📊]] Informe de carga del módulo:\n",
            "  - Módulo: dpm_SQL\n",
            "  - Ruta: /tmp/dpm_SQL.py\n",
            "  - Fecha de última modificación (último commit en GitHub o mod. local): 2025-03-11 17:34:28+01:00\n",
            "  - Objetos importados:\n",
            "      • DF_to_GBQ (function): Carga un DataFrame en una tabla de Google BigQuery e imprime un informe detallado con\n",
            "      • GBQ_execute_SQL (function): Ejecuta un script SQL en Google BigQuery y muestra un resumen detallado con estadísticas del proceso.\n",
            "      • SQL_generate_BI_view_str (function): Crea o reemplaza una vista (o tabla) BI, seleccionando columnas de una tabla fuente con mapeos y filtros.\n",
            "      • SQL_generate_CPL_to_contacts_str (function): Genera una sentencia SQL para crear o reemplazar una tabla que combina una tabla principal de contactos,\n",
            "      • SQL_generate_academic_date_str (function): Genera una sentencia SQL para crear o reemplazar una tabla con campos de fecha académica/fiscal,\n",
            "      • SQL_generate_cleaning_str (function): Genera una sentencia SQL para crear o sobrescribir una tabla de 'staging' aplicando mapeos, filtros\n",
            "      • SQL_generate_country_from_phone (function): Genera un script SQL para actualizar una tabla destino a partir de datos extraídos y procesados de:\n",
            "      • SQL_generate_country_name_mapping (function): Función unificada que:\n",
            "      • SQL_generate_deal_ordinal_str (function): Genera un script SQL que crea o reemplaza una tabla con un campo ordinal de negocio por contacto,\n",
            "      • SQL_generate_join_tables_str (function): Crea o reemplaza una tabla uniendo una tabla primaria, secundaria y opcionalmente una tabla puente,\n",
            "      • SQL_generate_new_columns_from_mapping (function): Genera un script SQL que agrega nuevas columnas a una tabla de BigQuery a partir de un mapeo\n",
            "      • SQL_generation_normalize_strings (function): Normaliza los valores de una columna en una tabla de BigQuery usando mapeo manual y fuzzy matching.\n",
            "\n",
            "[END [FINISHED ✅]] Módulo 'dpm_SQL' actualizado e importado en los builtins.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "U-hU3wVkrKz3",
        "outputId": "bd0c1712-9bd9-4e55-b933-7583d1d9dfce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El paquete 'whisper' no está instalado. Procediendo con la instalación...\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-fmgh_a8f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-fmgh_a8f\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2->openai-whisper==20240930) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m154.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m171.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803669 sha256=88f206d028867cbcd4d5b855487f323cbe52f45a27422b3c80ede674ada16e8e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nxb4ql3w/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n",
            "El paquete 'ffmpeg-python' no está instalado. Procediendo con la instalación...\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "FFmpeg ya está instalado.\n"
          ]
        }
      ],
      "source": [
        "# @title IMPORTACIÓN DE LIBRERÍAS WHISPER Y FFMPEG\n",
        "\n",
        "# Verificar e instalar el paquete 'whisper'\n",
        "try:\n",
        "    import whisper\n",
        "except ImportError:\n",
        "    print(\"El paquete 'whisper' no está instalado. Procediendo con la instalación...\")\n",
        "    !pip install git+https://github.com/openai/whisper.git\n",
        "    import whisper\n",
        "\n",
        "# Verificar e instalar el paquete 'ffmpeg-python'\n",
        "try:\n",
        "    import ffmpeg\n",
        "except ImportError:\n",
        "    print(\"El paquete 'ffmpeg-python' no está instalado. Procediendo con la instalación...\")\n",
        "    !pip install ffmpeg-python\n",
        "\n",
        "# Instalar y verificar 'ffmpeg' a nivel del sistema\n",
        "import os\n",
        "if os.system(\"ffmpeg -version\") != 0:\n",
        "    print(\"FFmpeg no está instalado. Procediendo con la instalación...\")\n",
        "    !apt-get update\n",
        "    !apt-get install -y ffmpeg\n",
        "    !ffmpeg -version\n",
        "else:\n",
        "    print(\"FFmpeg ya está instalado.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GBQ DATASETS SCHEMA"
      ],
      "metadata": {
        "id": "Teu_Q7OxO5nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GBQ INFO GLOBAL\n",
        "\n",
        "\n",
        "# Configuración\n",
        "params_dic = {\n",
        "    \"spreadsheet_source_table_id\": \"1aJCGTJtDu_ODqBc4zUcrpQ-q6PE_HN0rO4mwYMIhCXw\",\n",
        "    \"spreadsheet_source_table_worksheet_name\": \"DATA\",\n",
        "\n",
        "    \"ini_environment_identificated\": ini_environment_identificated,\n",
        "    \"json_keyfile_GCP_secret_id\": GCP_json_keyfile_GCP_secret_id,\n",
        "    \"json_keyfile_colab\": GCP_json_keyfile_colab\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "full_info_from_GBQ_df = table_various_sources_to_DF(params_dic)\n",
        "display(full_info_from_GBQ_df)"
      ],
      "metadata": {
        "id": "6rFSqt23O7ft",
        "outputId": "2b0236bf-89a8-48eb-c748-0014b73e5fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUTHENTICATION [INFO] 🔐] Entorno local/Colab detectado. Usando json_keyfile_colab.\n",
            "[EXTRACTION [START ⏳]] Extrayendo datos de Google Sheets...\n",
            "[EXTRACTION [SUCCESS ✅]] Datos extraídos con éxito de la hoja 'DATA'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    project_id     dataset_id       table_name  \\\n",
              "0     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "1     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "2     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "3     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "4     animum-dev-datawarehouse  IMDb_01raw_01  name_basics_raw   \n",
              "...                        ...            ...              ...   \n",
              "9688  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "9689  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "9690  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "9691  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "9692  animum-dev-datawarehouse    vl_01raw_01    MA_PROVINCIAS   \n",
              "\n",
              "                field_name field_type  num_rows num_columns size_mb  \\\n",
              "0                   nconst     STRING  14235647           6  865.54   \n",
              "1              primaryName     STRING  14235647           6  865.54   \n",
              "2                birthYear    INTEGER  14235647           6  865.54   \n",
              "3                deathYear     STRING  14235647           6  865.54   \n",
              "4        primaryProfession     STRING  14235647           6  865.54   \n",
              "...                    ...        ...       ...         ...     ...   \n",
              "9688         Hora_creacion   DATETIME      1033          10    0.06   \n",
              "9689      Usuario_creacion     STRING      1033          10    0.06   \n",
              "9690    Fecha_modificacion   DATETIME      1033          10    0.06   \n",
              "9691     Hora_modificacion   DATETIME      1033          10    0.06   \n",
              "9692  Usuario_modificacion     STRING      1033          10    0.06   \n",
              "\n",
              "     fecha_actualizacion_GBQ fecha_actualizacion_df  \n",
              "0        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "1        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "2        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "3        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "4        10/03/2025 19:43:37    11/03/2025 17:00:05  \n",
              "...                      ...                    ...  \n",
              "9688      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "9689      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "9690      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "9691      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "9692      10/03/2025 5:22:56    11/03/2025 17:00:05  \n",
              "\n",
              "[9693 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad589162-b035-40fe-a861-5d4b2414c657\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project_id</th>\n",
              "      <th>dataset_id</th>\n",
              "      <th>table_name</th>\n",
              "      <th>field_name</th>\n",
              "      <th>field_type</th>\n",
              "      <th>num_rows</th>\n",
              "      <th>num_columns</th>\n",
              "      <th>size_mb</th>\n",
              "      <th>fecha_actualizacion_GBQ</th>\n",
              "      <th>fecha_actualizacion_df</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>nconst</td>\n",
              "      <td>STRING</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>primaryName</td>\n",
              "      <td>STRING</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>birthYear</td>\n",
              "      <td>INTEGER</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>deathYear</td>\n",
              "      <td>STRING</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>IMDb_01raw_01</td>\n",
              "      <td>name_basics_raw</td>\n",
              "      <td>primaryProfession</td>\n",
              "      <td>STRING</td>\n",
              "      <td>14235647</td>\n",
              "      <td>6</td>\n",
              "      <td>865.54</td>\n",
              "      <td>10/03/2025 19:43:37</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9688</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Hora_creacion</td>\n",
              "      <td>DATETIME</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9689</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Usuario_creacion</td>\n",
              "      <td>STRING</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9690</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Fecha_modificacion</td>\n",
              "      <td>DATETIME</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9691</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Hora_modificacion</td>\n",
              "      <td>DATETIME</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9692</th>\n",
              "      <td>animum-dev-datawarehouse</td>\n",
              "      <td>vl_01raw_01</td>\n",
              "      <td>MA_PROVINCIAS</td>\n",
              "      <td>Usuario_modificacion</td>\n",
              "      <td>STRING</td>\n",
              "      <td>1033</td>\n",
              "      <td>10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10/03/2025 5:22:56</td>\n",
              "      <td>11/03/2025 17:00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9693 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad589162-b035-40fe-a861-5d4b2414c657')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad589162-b035-40fe-a861-5d4b2414c657 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad589162-b035-40fe-a861-5d4b2414c657');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0f56f4c-814d-408a-af80-1a432a3e4edf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0f56f4c-814d-408a-af80-1a432a3e4edf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0f56f4c-814d-408a-af80-1a432a3e4edf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_52165233-607b-4f70-9d7f-f1f8dbaa6619\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('full_info_from_GBQ_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_52165233-607b-4f70-9d7f-f1f8dbaa6619 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('full_info_from_GBQ_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "full_info_from_GBQ_df",
              "summary": "{\n  \"name\": \"full_info_from_GBQ_df\",\n  \"rows\": 9693,\n  \"fields\": [\n    {\n      \"column\": \"project_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"animum-dev-datawarehouse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"hubspot_raw_v01_hubspot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"table_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 443,\n        \"samples\": [\n          \"stg_hubspot__deal_tmp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3637,\n        \"samples\": [\n          \"active_user_id\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"INTEGER\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_rows\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 323,\n        \"samples\": [\n          \"323\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_columns\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 66,\n        \"samples\": [\n          \"84\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size_mb\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 233,\n        \"samples\": [\n          \"6.83\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fecha_actualizacion_GBQ\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 341,\n        \"samples\": [\n          \"10/03/2025 5:19:57\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fecha_actualizacion_df\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"11/03/2025 17:00:05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GBQ DATASETS\n",
        "print(\"Datasets disponibles:\\n\")\n",
        "for dataset in full_info_from_GBQ_df['dataset_id'].unique():\n",
        "    print(f\"{dataset}\")"
      ],
      "metadata": {
        "id": "zT0CjPsKO9Tt",
        "outputId": "1577218e-5394-4fb4-c4d4-5684f43f2a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets disponibles:\n",
            "\n",
            "IMDb_01raw_01\n",
            "IMDb_02st_01\n",
            "IMDb_raw_01\n",
            "IMDb_staging_01\n",
            "cd2_01raw_01\n",
            "facebook_ads_raw_v01\n",
            "facebook_ads_raw_v01_facebook_ads\n",
            "facebook_ads_raw_v01_facebook_ads_source\n",
            "fivetran_metadata\n",
            "fivetran_metadata_fivetran_platform\n",
            "fivetran_metadata_stg_fivetran_platform\n",
            "google_ads_raw_01\n",
            "google_ads_raw_01_google_ads\n",
            "google_ads_raw_01_google_ads_source\n",
            "hubspot_raw_v01\n",
            "hubspot_raw_v01_hubspot\n",
            "hubspot_raw_v01_stg_hubspot\n",
            "mkt_02st_01\n",
            "mkt_03BI_01\n",
            "tablas_mapeo\n",
            "tp_02st_01\n",
            "tp_03bi_01\n",
            "vl_01raw_01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjCHetu3qgUD"
      },
      "source": [
        "# DECLARACIÓN DE FUNCIONES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw6MOjDMlucz"
      },
      "outputs": [],
      "source": [
        "# @title get_video_properties_dic()\n",
        "def get_video_properties_dic(params: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Obtiene las propiedades técnicas de un archivo de video.\n",
        "    Args:\n",
        "        params (dict):\n",
        "            - file_path (str): Ruta completa del archivo de video.\n",
        "    Returns:\n",
        "        dict: Diccionario con las siguientes claves:\n",
        "            - file_name (str): Nombre del archivo de video.\n",
        "            - file_path (str): Ruta completa del archivo de video.\n",
        "            - file_size_mb (float): Tamaño del archivo en megabytes.\n",
        "            - duration_s (float): Duración del video en segundos.\n",
        "            - video_codec (str): Códec de video utilizado.\n",
        "            - audio_codec (str): Códec de audio utilizado.\n",
        "            - resolution (str): Resolución del video (ancho x alto).\n",
        "            - audio_sample_rate (int): Frecuencia de muestreo del audio en Hz.\n",
        "            - error (str): Mensaje de error en caso de fallo (opcional).\n",
        "    \"\"\"\n",
        "    file_path = params.get(\"file_path\")\n",
        "    try:\n",
        "        probe = ffmpeg.probe(file_path)\n",
        "        video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
        "        audio_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'audio'), None)\n",
        "\n",
        "        return {\n",
        "            \"file_name\": os.path.basename(file_path),\n",
        "            \"file_path\": file_path,\n",
        "            \"file_size_mb\": float(probe['format']['size']) / (1024 * 1024),\n",
        "            \"duration_s\": float(probe['format']['duration']),\n",
        "            \"video_codec\": video_stream['codec_name'] if video_stream else None,\n",
        "            \"audio_codec\": audio_stream['codec_name'] if audio_stream else None,\n",
        "            \"resolution\": f\"{video_stream['width']}x{video_stream['height']}\" if video_stream else None,\n",
        "            \"audio_sample_rate\": int(audio_stream['sample_rate']) if audio_stream else None,\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"file_name\": os.path.basename(file_path),\n",
        "            \"file_path\": file_path,\n",
        "            \"file_size_mb\": None,\n",
        "            \"duration_s\": None,\n",
        "            \"video_codec\": None,\n",
        "            \"audio_codec\": None,\n",
        "            \"resolution\": None,\n",
        "            \"audio_sample_rate\": None,\n",
        "            \"error\": str(e)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt-aVYsgpT1o"
      },
      "outputs": [],
      "source": [
        "# @title orchestrate_transcription_to_GSpread()\n",
        "def orchestrate_transcription_to_GSpread(params: dict):\n",
        "    \"\"\"\n",
        "    Orquesta el proceso de transcripción de videos en una carpeta y actualiza\n",
        "    una hoja de Google Sheets con columnas fijas, incluyendo hasta 10 partes\n",
        "    de transcripción (de 50k caracteres cada una).\n",
        "\n",
        "    Escribe cada transcripción inmediatamente, para no perder avances si\n",
        "    la sesión se interrumpe.\n",
        "\n",
        "    Args:\n",
        "        params (dict):\n",
        "            - folder_path (str): Ruta de la carpeta con los videos.\n",
        "            - model_size (str): Tamaño del modelo Whisper (\"tiny\", \"base\", \"small\", \"medium\", \"large\").\n",
        "            - sheet_id (str | None): ID de la hoja de Google Sheets; si no se da, se crea una nueva.\n",
        "            - verbose (bool): Mostrar mensajes detallados durante el proceso.\n",
        "    \"\"\"\n",
        "    import gspread\n",
        "    from google.colab import auth\n",
        "    from google.auth.transport.requests import Request\n",
        "    from google.auth import default\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "    import time\n",
        "    import ffmpeg\n",
        "    import pandas as pd\n",
        "    from whisper import load_model\n",
        "    from IPython.display import display\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 1) Autenticar en Google y abrir/crear la hoja\n",
        "    # ------------------------------------------------------------------------\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    creds.refresh(Request())\n",
        "    gspread_client = gspread.authorize(creds)\n",
        "\n",
        "    sheet_id = params.get(\"sheet_id\")\n",
        "    if sheet_id:\n",
        "        try:\n",
        "            spreadsheet = gspread_client.open_by_key(sheet_id)\n",
        "        except gspread.SpreadsheetNotFound:\n",
        "            raise ValueError(\"El ID proporcionado no corresponde a una hoja válida.\")\n",
        "    else:\n",
        "        folder_name = os.path.basename(params[\"folder_path\"])\n",
        "        sheet_name = \"Transcripciones de Videos\"\n",
        "        spreadsheet = gspread_client.create(f\"{folder_name} - {sheet_name}\")\n",
        "\n",
        "    sheet = spreadsheet.sheet1\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 2) Definir cabecera fija y verificar si la hoja ya la tiene\n",
        "    # ------------------------------------------------------------------------\n",
        "    HEADERS = [\n",
        "        \"file_name\", \"file_path\", \"file_size_mb\", \"duration_s\",\n",
        "        \"video_codec\", \"audio_codec\", \"resolution\", \"audio_sample_rate\",\n",
        "        \"transcription_date\",\n",
        "        \"transcription_part_1\", \"transcription_part_2\", \"transcription_part_3\",\n",
        "        \"transcription_part_4\", \"transcription_part_5\", \"transcription_part_6\",\n",
        "        \"transcription_part_7\", \"transcription_part_8\", \"transcription_part_9\",\n",
        "        \"transcription_part_10\"\n",
        "    ]\n",
        "\n",
        "    existing_values = sheet.get_all_values()\n",
        "    if existing_values:\n",
        "        current_headers = existing_values[0]\n",
        "        # Chequeamos si 'file_name' no existe o si la cantidad de columnas\n",
        "        # es distinta a la que esperamos (19), limpiamos y reescribimos.\n",
        "        if (\"file_name\" not in current_headers) or (len(current_headers) != len(HEADERS)):\n",
        "            sheet.clear()\n",
        "            sheet.update(\"A1\", [HEADERS])\n",
        "    else:\n",
        "        # Hoja en blanco\n",
        "        sheet.update(\"A1\", [HEADERS])\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 3) Leer registros existentes para saber qué archivos se han transcrito\n",
        "    # ------------------------------------------------------------------------\n",
        "    all_rows = sheet.get_all_records()\n",
        "    processed_files = {\n",
        "        row.get(\"file_name\"): row.get(\"transcription_date\", \"N/A\")\n",
        "        for row in all_rows\n",
        "        if row.get(\"file_name\") is not None\n",
        "    }\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 4) Listar archivos y mostrar estado\n",
        "    # ------------------------------------------------------------------------\n",
        "    folder_path = params[\"folder_path\"]\n",
        "    video_files = [\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith((\".mp4\", \".mkv\", \".avi\", \".mov\"))\n",
        "    ]\n",
        "    status_data = []\n",
        "    for video in video_files:\n",
        "        status = \"Transcrito\" if video in processed_files else \"No transcrito\"\n",
        "        date = processed_files.get(video, \"N/A\")\n",
        "        status_data.append({\"file_name\": video, \"status\": status, \"transcription_date\": date})\n",
        "\n",
        "    status_df = pd.DataFrame(status_data)\n",
        "    print(\"\\nEstado de los vídeos:\")\n",
        "    display(status_df)\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 5) Cargar modelo Whisper\n",
        "    # ------------------------------------------------------------------------\n",
        "    model = load_model(params.get(\"model_size\", \"medium\"))\n",
        "    if params.get(\"verbose\", False):\n",
        "        print(f\"\\nModelo '{params.get('model_size', 'medium')}' cargado correctamente.\")\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    # 6) Transcribir cada video y volcar de inmediato a la hoja\n",
        "    # ------------------------------------------------------------------------\n",
        "    max_chars = 50000  # troceamos la transcripción en bloques de 50k para evitar errores en GSheet\n",
        "\n",
        "    for video in video_files:\n",
        "        # Saltar si ya está transcrito\n",
        "        if video in processed_files:\n",
        "            if params.get(\"verbose\", False):\n",
        "                print(f\"Saltando archivo ya procesado: {video}\")\n",
        "            continue\n",
        "\n",
        "        video_path = os.path.join(folder_path, video)\n",
        "\n",
        "        # Obtener metadatos del video (necesita get_video_properties_dic)\n",
        "        properties = get_video_properties_dic({\"file_path\": video_path})\n",
        "\n",
        "        # Transcribir\n",
        "        transcription = \"\"\n",
        "        try:\n",
        "            if params.get(\"verbose\", False):\n",
        "                print(f\"\\nProcesando: {video}\")\n",
        "            result = model.transcribe(video_path, language='es')\n",
        "            transcription = result[\"text\"]\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribiendo {video}: {e}\")\n",
        "            transcription = \"\"\n",
        "\n",
        "        # Trocear en bloques de 50k\n",
        "        transcription_parts = [\n",
        "            transcription[i : i + max_chars]\n",
        "            for i in range(0, len(transcription), max_chars)\n",
        "        ]\n",
        "\n",
        "        # Asignar un máximo de 10 partes\n",
        "        if len(transcription_parts) > 10:\n",
        "            # Concatenar el resto en la última parte\n",
        "            sobrante = \"\".join(transcription_parts[10:])\n",
        "            transcription_parts[9] += sobrante\n",
        "            transcription_parts = transcription_parts[:10]\n",
        "\n",
        "        # Preparar lista de 10 partes (rellenando con \"\")\n",
        "        transcription_parts += [\"\"] * (10 - len(transcription_parts))\n",
        "\n",
        "        # Construir la fila en el orden de HEADERS\n",
        "        row_values = [\n",
        "            properties.get(\"file_name\"),\n",
        "            properties.get(\"file_path\"),\n",
        "            properties.get(\"file_size_mb\"),\n",
        "            properties.get(\"duration_s\"),\n",
        "            properties.get(\"video_codec\"),\n",
        "            properties.get(\"audio_codec\"),\n",
        "            properties.get(\"resolution\"),\n",
        "            properties.get(\"audio_sample_rate\"),\n",
        "            datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),   # transcription_date\n",
        "        ] + transcription_parts  # las 10 columnas\n",
        "\n",
        "        # Insertar la fila en la hoja\n",
        "        reintentos = 3\n",
        "        for intento in range(reintentos):\n",
        "            try:\n",
        "                sheet.append_row(row_values, value_input_option=\"USER_ENTERED\")\n",
        "                if params.get(\"verbose\", False):\n",
        "                    print(f\"Actualizado en Google Sheets: {video}\")\n",
        "                break\n",
        "            except gspread.exceptions.APIError as e:\n",
        "                if intento < reintentos - 1:\n",
        "                    print(f\"Error al actualizar Google Sheets. Reintentando ({intento + 1}/{reintentos})...\")\n",
        "                    time.sleep(5)\n",
        "                else:\n",
        "                    print(f\"Error persistente al actualizar Google Sheets: {e}\")\n",
        "\n",
        "    print(f\"\\nProceso completado. Hoja de cálculo disponible en: {spreadsheet.url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KV9LQYVLoDFP",
        "outputId": "018ad557-cf57-47d5-edc1-9634738ce902"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Estado de los vídeos:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"orchestrate_transcription_to_GSpread(param)\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"03 - Gestio\\u0301n Financiera 2-20240607_100241.mp4\",\n          \"03 - Gestio\\u0301n Financiera 2 20240607.mp4\",\n          \"04 - Compras y pagos-20240611_115156.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"No transcrito\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcription_date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7ce27598-761e-4ef1-aabe-5e69d0104625\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>status</th>\n",
              "      <th>transcription_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03 - Gestión Financiera 2-20240607_100241.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>03 - Gestión Financiera 2 20240607.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01 - Ventas y Cobros-20240604_120138 - v1.0 20...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01 - Ventas y Cobros-20240604_100548 - v1.0 20...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07 - Sesión análisis Tesorería  2-20240618_...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>06 - Sesión análisis Tesoreria  1-20240617_1...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>05 - Compras y pagos 2-20240612_113249.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>05 - Compras y pagos 2-20240612_100906.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>04 - Compras y pagos-20240611_115156.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>04 - Compras y pagos-20240611_105212.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>02 - Gestión Financiera-20240606_115103.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>02 - Gestión Financiera-20240606_103808.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>08 - Sesión análisis Marketing-20240619_1138...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>09 - Sesión análisis Proyectos recursos-2024...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10 - Sesión análisis RRHH-20240710_101033.mp4</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>11 - Sesión aclarar Dimensiones y Informes Ta...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>12 - Reunión resolución de dudas-20240712_09...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>13 - Sesión trabajo ingresos por módulo-2024...</td>\n",
              "      <td>No transcrito</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ce27598-761e-4ef1-aabe-5e69d0104625')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ce27598-761e-4ef1-aabe-5e69d0104625 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ce27598-761e-4ef1-aabe-5e69d0104625');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19f3700a-740d-40fc-88af-cfb36f51c1c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19f3700a-740d-40fc-88af-cfb36f51c1c3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19f3700a-740d-40fc-88af-cfb36f51c1c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            file_name         status  \\\n",
              "0      03 - Gestión Financiera 2-20240607_100241.mp4  No transcrito   \n",
              "1             03 - Gestión Financiera 2 20240607.mp4  No transcrito   \n",
              "2   01 - Ventas y Cobros-20240604_120138 - v1.0 20...  No transcrito   \n",
              "3   01 - Ventas y Cobros-20240604_100548 - v1.0 20...  No transcrito   \n",
              "4   07 - Sesión análisis Tesorería  2-20240618_...  No transcrito   \n",
              "5   06 - Sesión análisis Tesoreria  1-20240617_1...  No transcrito   \n",
              "6          05 - Compras y pagos 2-20240612_113249.mp4  No transcrito   \n",
              "7          05 - Compras y pagos 2-20240612_100906.mp4  No transcrito   \n",
              "8            04 - Compras y pagos-20240611_115156.mp4  No transcrito   \n",
              "9            04 - Compras y pagos-20240611_105212.mp4  No transcrito   \n",
              "10       02 - Gestión Financiera-20240606_115103.mp4  No transcrito   \n",
              "11       02 - Gestión Financiera-20240606_103808.mp4  No transcrito   \n",
              "12  08 - Sesión análisis Marketing-20240619_1138...  No transcrito   \n",
              "13  09 - Sesión análisis Proyectos recursos-2024...  No transcrito   \n",
              "14    10 - Sesión análisis RRHH-20240710_101033.mp4  No transcrito   \n",
              "15  11 - Sesión aclarar Dimensiones y Informes Ta...  No transcrito   \n",
              "16  12 - Reunión resolución de dudas-20240712_09...  No transcrito   \n",
              "17  13 - Sesión trabajo ingresos por módulo-2024...  No transcrito   \n",
              "\n",
              "   transcription_date  \n",
              "0                 N/A  \n",
              "1                 N/A  \n",
              "2                 N/A  \n",
              "3                 N/A  \n",
              "4                 N/A  \n",
              "5                 N/A  \n",
              "6                 N/A  \n",
              "7                 N/A  \n",
              "8                 N/A  \n",
              "9                 N/A  \n",
              "10                N/A  \n",
              "11                N/A  \n",
              "12                N/A  \n",
              "13                N/A  \n",
              "14                N/A  \n",
              "15                N/A  \n",
              "16                N/A  \n",
              "17                N/A  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:15<00:00, 95.8MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo 'medium' cargado correctamente.\n",
            "\n",
            "Procesando: 03 - Gestión Financiera 2-20240607_100241.mp4\n",
            "Actualizado en Google Sheets: 03 - Gestión Financiera 2-20240607_100241.mp4\n",
            "\n",
            "Procesando: 03 - Gestión Financiera 2 20240607.mp4\n",
            "Actualizado en Google Sheets: 03 - Gestión Financiera 2 20240607.mp4\n",
            "\n",
            "Procesando: 01 - Ventas y Cobros-20240604_120138 - v1.0 20240624.mp4\n",
            "Actualizado en Google Sheets: 01 - Ventas y Cobros-20240604_120138 - v1.0 20240624.mp4\n",
            "\n",
            "Procesando: 01 - Ventas y Cobros-20240604_100548 - v1.0 20240604.mp4\n",
            "Actualizado en Google Sheets: 01 - Ventas y Cobros-20240604_100548 - v1.0 20240604.mp4\n",
            "\n",
            "Procesando: 07 - Sesión análisis Tesorería  2-20240618_100526.mp4\n",
            "Actualizado en Google Sheets: 07 - Sesión análisis Tesorería  2-20240618_100526.mp4\n",
            "\n",
            "Procesando: 06 - Sesión análisis Tesoreria  1-20240617_100524.mp4\n",
            "Actualizado en Google Sheets: 06 - Sesión análisis Tesoreria  1-20240617_100524.mp4\n",
            "\n",
            "Procesando: 05 - Compras y pagos 2-20240612_113249.mp4\n",
            "Actualizado en Google Sheets: 05 - Compras y pagos 2-20240612_113249.mp4\n",
            "\n",
            "Procesando: 05 - Compras y pagos 2-20240612_100906.mp4\n",
            "Error al actualizar Google Sheets. Reintentando (1/3)...\n",
            "Actualizado en Google Sheets: 05 - Compras y pagos 2-20240612_100906.mp4\n",
            "\n",
            "Procesando: 04 - Compras y pagos-20240611_115156.mp4\n",
            "Actualizado en Google Sheets: 04 - Compras y pagos-20240611_115156.mp4\n",
            "\n",
            "Procesando: 04 - Compras y pagos-20240611_105212.mp4\n",
            "Actualizado en Google Sheets: 04 - Compras y pagos-20240611_105212.mp4\n",
            "\n",
            "Procesando: 02 - Gestión Financiera-20240606_115103.mp4\n",
            "Actualizado en Google Sheets: 02 - Gestión Financiera-20240606_115103.mp4\n",
            "\n",
            "Procesando: 02 - Gestión Financiera-20240606_103808.mp4\n",
            "Actualizado en Google Sheets: 02 - Gestión Financiera-20240606_103808.mp4\n",
            "\n",
            "Procesando: 08 - Sesión análisis Marketing-20240619_113823.mp4\n",
            "Actualizado en Google Sheets: 08 - Sesión análisis Marketing-20240619_113823.mp4\n",
            "\n",
            "Procesando: 09 - Sesión análisis Proyectos recursos-20240619_100514.mp4\n",
            "Actualizado en Google Sheets: 09 - Sesión análisis Proyectos recursos-20240619_100514.mp4\n",
            "\n",
            "Procesando: 10 - Sesión análisis RRHH-20240710_101033.mp4\n",
            "Actualizado en Google Sheets: 10 - Sesión análisis RRHH-20240710_101033.mp4\n",
            "\n",
            "Procesando: 11 - Sesión aclarar Dimensiones y Informes Tableau-20240710_110806.mp4\n",
            "Actualizado en Google Sheets: 11 - Sesión aclarar Dimensiones y Informes Tableau-20240710_110806.mp4\n",
            "\n",
            "Procesando: 12 - Reunión resolución de dudas-20240712_093536.mp4\n",
            "Actualizado en Google Sheets: 12 - Reunión resolución de dudas-20240712_093536.mp4\n",
            "\n",
            "Procesando: 13 - Sesión trabajo ingresos por módulo-20240718_110628.mp4\n",
            "Actualizado en Google Sheets: 13 - Sesión trabajo ingresos por módulo-20240718_110628.mp4\n",
            "\n",
            "Proceso completado. Hoja de cálculo disponible en: https://docs.google.com/spreadsheets/d/18esoAyRzemkA3GLVTDV6k45U5KqQzkrULYt3sE99KiQ\n"
          ]
        }
      ],
      "source": [
        "#@title Configuración\n",
        "import os\n",
        "import time\n",
        "import ffmpeg\n",
        "import pandas as pd\n",
        "from whisper import load_model\n",
        "\n",
        "# Diccionario de configuración\n",
        "folder_path = r\"/content/drive/Shareddrives/AREA TIC COMPARTIDO USUARIOS EXTERNOS/ERP v6.0 - PROYECTO G-F (AYESA)/50 - BC/10 - DAF/Videos Sesiones DAF/\" #@param {type:\"string\"}\n",
        "model_size = \"medium\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
        "sheet_id = \"18esoAyRzemkA3GLVTDV6k45U5KqQzkrULYt3sE99KiQ\" # o None\n",
        "param = {\n",
        "    \"folder_path\": folder_path,\n",
        "    \"model_size\": model_size,\n",
        "    \"sheet_id\": sheet_id,  # ID de la hoja de Google Sheets,\n",
        "    \"verbose\": True  # Activar detalles adicionales\n",
        "}\n",
        "\n",
        "\n",
        "# Ejecutar el proceso orquestado\n",
        "orchestrate_transcription_to_GSpread(param)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title video_whisper_transcribe_to()\n",
        "def video_whisper_transcribe_to(params: dict) -> None:\n",
        "    \"\"\"\n",
        "    Orquesta la transcripción de archivos de video en una carpeta utilizando el modelo Whisper y actualiza\n",
        "    una hoja de Google Sheets con los metadatos técnicos y la transcripción dividida en hasta 10 partes.\n",
        "\n",
        "    Args:\n",
        "        params (dict):\n",
        "            - folder_path (str): Ruta de la carpeta que contiene los videos. [OBLIGATORIO]\n",
        "            - model_size (str): Tamaño del modelo Whisper (\"tiny\", \"base\", \"small\", \"medium\", \"large\"). Default: \"medium\".\n",
        "            - sheet_id (str | None): ID de la hoja de Google Sheets; si no se proporciona, se creará una nueva.\n",
        "            - verbose (bool): Indica si se muestran mensajes detallados. Default: False.\n",
        "            - ini_environment_identificated (str): Identificador del entorno. Opciones: \"LOCAL\", \"COLAB\", \"COLAB_ENTERPRISE\" o un project_id.\n",
        "            - json_keyfile_local (str): (Requerido en entorno LOCAL) Ruta al archivo JSON de credenciales.\n",
        "            - json_keyfile_colab (str): (Requerido en entornos COLAB) Ruta al archivo JSON de credenciales.\n",
        "            - json_keyfile_GCP_secret_id (str): (Requerido en entornos GCP) Secret ID del JSON de credenciales en Secret Manager.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        ValueError: Si faltan parámetros obligatorios o se produce un error durante la autenticación.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import json\n",
        "    import time\n",
        "    import ffmpeg\n",
        "    from datetime import datetime\n",
        "    from google.oauth2.service_account import Credentials\n",
        "\n",
        "    # ────────────────────────────── VALIDACIÓN DE PARÁMETROS ──────────────────────────────\n",
        "    if not params.get(\"folder_path\"):\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] Falta el parámetro 'folder_path' en params.\")\n",
        "    folder_path_str = params.get(\"folder_path\")\n",
        "    if not os.path.exists(folder_path_str):\n",
        "        raise ValueError(f\"[VALIDATION [ERROR ❌]] La ruta indicada no existe: {folder_path_str}\")\n",
        "    model_size_str = params.get(\"model_size\", \"medium\")\n",
        "    verbose_bool = params.get(\"verbose\", False)\n",
        "\n",
        "    print(\"[START ▶️] Inicio del proceso de transcripción de videos.\", flush=True)\n",
        "\n",
        "    # ────────────────────────────── AUTENTICACIÓN Y ACCESO A GOOGLE SHEETS ──────────────────────────────\n",
        "    env_str = params.get(\"ini_environment_identificated\")\n",
        "    if not env_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] Falta el parámetro 'ini_environment_identificated' en params.\")\n",
        "\n",
        "    if env_str == \"LOCAL\":\n",
        "        json_keyfile_local_str = params.get(\"json_keyfile_local\")\n",
        "        if not json_keyfile_local_str:\n",
        "            raise ValueError(\"[VALIDATION [ERROR ❌]] En entorno LOCAL se debe proporcionar 'json_keyfile_local' en params.\")\n",
        "        print(\"[AUTHENTICATION [START ▶️]] Iniciando autenticación en entorno LOCAL mediante JSON de credenciales...\", flush=True)\n",
        "        try:\n",
        "            creds = Credentials.from_service_account_file(json_keyfile_local_str)\n",
        "            print(\"[AUTHENTICATION [SUCCESS ✅]] Autenticación en entorno LOCAL completada.\", flush=True)\n",
        "        except Exception as error_local:\n",
        "            raise ValueError(f\"[AUTHENTICATION [ERROR ❌]] Error durante la autenticación en entorno LOCAL: {error_local}\")\n",
        "    elif env_str == \"COLAB\":\n",
        "        json_keyfile_colab_str = params.get(\"json_keyfile_colab\")\n",
        "        if not json_keyfile_colab_str:\n",
        "            raise ValueError(\"[VALIDATION [ERROR ❌]] En entornos COLAB se debe proporcionar 'json_keyfile_colab' en params.\")\n",
        "        print(\"[AUTHENTICATION [START ▶️]] Iniciando autenticación en entorno COLAB mediante JSON de credenciales...\", flush=True)\n",
        "        try:\n",
        "            creds = Credentials.from_service_account_file(json_keyfile_colab_str)\n",
        "            print(\"[AUTHENTICATION [SUCCESS ✅]] Autenticación en entorno COLAB completada.\", flush=True)\n",
        "        except Exception as error_colab:\n",
        "            raise ValueError(f\"[AUTHENTICATION [ERROR ❌]] Error durante la autenticación en COLAB: {error_colab}\")\n",
        "    elif env_str == \"COLAB_ENTERPRISE\" or (env_str not in [\"LOCAL\", \"COLAB\"]):\n",
        "        # Para COLAB_ENTERPRISE o cuando se pasa un project_id directamente\n",
        "        if env_str == \"COLAB_ENTERPRISE\":\n",
        "            project_id_env = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "            if not project_id_env:\n",
        "                raise ValueError(\"[VALIDATION [ERROR ❌]] No se encontró la variable de entorno 'GOOGLE_CLOUD_PROJECT'.\")\n",
        "        else:\n",
        "            project_id_env = env_str\n",
        "        json_keyfile_GCP_secret_id_str = params.get(\"json_keyfile_GCP_secret_id\")\n",
        "        if not json_keyfile_GCP_secret_id_str:\n",
        "            raise ValueError(\"[VALIDATION [ERROR ❌]] En entornos GCP se debe proporcionar 'json_keyfile_GCP_secret_id' en params.\")\n",
        "        print(\"[AUTHENTICATION [START ▶️]] Iniciando autenticación en entorno GCP mediante Secret Manager...\", flush=True)\n",
        "        try:\n",
        "            from google.cloud import secretmanager\n",
        "            client_sm = secretmanager.SecretManagerServiceClient()\n",
        "            secret_name = f\"projects/{project_id_env}/secrets/{json_keyfile_GCP_secret_id_str}/versions/latest\"\n",
        "            response = client_sm.access_secret_version(name=secret_name)\n",
        "            secret_string = response.payload.data.decode(\"UTF-8\")\n",
        "            secret_info = json.loads(secret_string)\n",
        "            creds = Credentials.from_service_account_info(secret_info)\n",
        "            print(f\"[AUTHENTICATION [SUCCESS ✅]] Autenticación en entorno GCP completada. (Secret Manager: {json_keyfile_GCP_secret_id_str})\", flush=True)\n",
        "        except Exception as error_gcp:\n",
        "            raise ValueError(f\"[AUTHENTICATION [ERROR ❌]] Error durante la autenticación en GCP: {error_gcp}\")\n",
        "\n",
        "    try:\n",
        "        import gspread\n",
        "        gspread_client = gspread.authorize(creds)\n",
        "    except Exception as error_gs:\n",
        "        raise Exception(f\"[AUTHENTICATION [ERROR ❌]] Error al autorizar Google Sheets: {error_gs}\")\n",
        "\n",
        "    # ────────────────────────────── SUBFUNCIÓN: Obtener propiedades del video ──────────────────────────────\n",
        "    def _get_video_properties_dic(file_path_str: str) -> dict:\n",
        "        \"\"\"\n",
        "        Extrae las propiedades técnicas del video.\n",
        "\n",
        "        Args:\n",
        "            file_path_str (str): Ruta completa del archivo de video.\n",
        "\n",
        "        Returns:\n",
        "            dict: Diccionario con metadatos técnicos.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"[EXTRACTION [START ▶️]] Extrayendo metadatos de: {os.path.basename(file_path_str)}\", flush=True)\n",
        "            probe_dic = ffmpeg.probe(file_path_str)\n",
        "            video_stream_dic = next((stream for stream in probe_dic['streams'] if stream['codec_type'] == 'video'), None)\n",
        "            audio_stream_dic = next((stream for stream in probe_dic['streams'] if stream['codec_type'] == 'audio'), None)\n",
        "            properties_dic = {\n",
        "                \"file_name\": os.path.basename(file_path_str),\n",
        "                \"file_path\": file_path_str,\n",
        "                \"file_size_mb\": float(probe_dic['format']['size']) / (1024 * 1024),\n",
        "                \"duration_s\": float(probe_dic['format']['duration']),\n",
        "                \"video_codec\": video_stream_dic['codec_name'] if video_stream_dic else None,\n",
        "                \"audio_codec\": audio_stream_dic['codec_name'] if audio_stream_dic else None,\n",
        "                \"resolution\": f\"{video_stream_dic['width']}x{video_stream_dic['height']}\" if video_stream_dic else None,\n",
        "                \"audio_sample_rate\": int(audio_stream_dic['sample_rate']) if audio_stream_dic else None,\n",
        "            }\n",
        "            print(\"[EXTRACTION [SUCCESS ✅]] Metadatos extraídos correctamente.\", flush=True)\n",
        "            return properties_dic\n",
        "        except Exception as error_meta:\n",
        "            print(f\"[EXTRACTION [ERROR ❌]] Error al extraer metadatos: {error_meta}\", flush=True)\n",
        "            return {\n",
        "                \"file_name\": os.path.basename(file_path_str),\n",
        "                \"file_path\": file_path_str,\n",
        "                \"file_size_mb\": None,\n",
        "                \"duration_s\": None,\n",
        "                \"video_codec\": None,\n",
        "                \"audio_codec\": None,\n",
        "                \"resolution\": None,\n",
        "                \"audio_sample_rate\": None,\n",
        "                \"error\": str(error_meta)\n",
        "            }\n",
        "\n",
        "    # ────────────────────────────── APERTURA O CREACIÓN DE LA HOJA DE CÁLCULO ──────────────────────────────\n",
        "    sheet_id_str = params.get(\"sheet_id\")\n",
        "    try:\n",
        "        if sheet_id_str:\n",
        "            spreadsheet = gspread_client.open_by_key(sheet_id_str)\n",
        "            print(f\"[LOAD [INFO ℹ️]] Hoja encontrada con ID: {sheet_id_str}\", flush=True)\n",
        "        else:\n",
        "            folder_name_str = os.path.basename(folder_path_str)\n",
        "            sheet_name_str = \"Transcripciones de Videos\"\n",
        "            spreadsheet = gspread_client.create(f\"{folder_name_str} - {sheet_name_str}\")\n",
        "            print(f\"[LOAD [INFO ℹ️]] Hoja creada: {spreadsheet.title}\", flush=True)\n",
        "    except Exception as error_sheet:\n",
        "        raise Exception(f\"[LOAD [ERROR ❌]] Error al acceder/crear la hoja de cálculo: {error_sheet}\")\n",
        "\n",
        "    sheet = spreadsheet.sheet1\n",
        "\n",
        "    # ────────────────────────────── CONFIGURACIÓN DE CABECERAS ──────────────────────────────\n",
        "    HEADERS_list = [\n",
        "        \"file_name\", \"file_path\", \"file_size_mb\", \"duration_s\",\n",
        "        \"video_codec\", \"audio_codec\", \"resolution\", \"audio_sample_rate\",\n",
        "        \"transcription_date\",\n",
        "        \"transcription_part_1\", \"transcription_part_2\", \"transcription_part_3\",\n",
        "        \"transcription_part_4\", \"transcription_part_5\", \"transcription_part_6\",\n",
        "        \"transcription_part_7\", \"transcription_part_8\", \"transcription_part_9\",\n",
        "        \"transcription_part_10\"\n",
        "    ]\n",
        "    try:\n",
        "        existing_values_list = sheet.get_all_values()\n",
        "        if existing_values_list:\n",
        "            current_headers_list = existing_values_list[0]\n",
        "            if (\"file_name\" not in current_headers_list) or (len(current_headers_list) != len(HEADERS_list)):\n",
        "                sheet.clear()\n",
        "                sheet.update(\"A1\", [HEADERS_list])\n",
        "                print(\"[LOAD [INFO ℹ️]] Cabecera actualizada en la hoja.\", flush=True)\n",
        "        else:\n",
        "            sheet.update(\"A1\", [HEADERS_list])\n",
        "            print(\"[LOAD [INFO ℹ️]] Cabecera inicializada en la hoja.\", flush=True)\n",
        "    except Exception as error_headers:\n",
        "        print(f\"[LOAD [ERROR ❌]] Error al configurar la cabecera: {error_headers}\", flush=True)\n",
        "\n",
        "    # ────────────────────────────── LECTURA DE REGISTROS EXISTENTES ──────────────────────────────\n",
        "    all_rows_list = sheet.get_all_records()\n",
        "    processed_files_dic = {\n",
        "        row.get(\"file_name\"): row.get(\"transcription_date\", \"N/A\")\n",
        "        for row in all_rows_list if row.get(\"file_name\") is not None\n",
        "    }\n",
        "\n",
        "    # ────────────────────────────── LISTADO DE ARCHIVOS DE VIDEO ──────────────────────────────\n",
        "    video_files_list = [\n",
        "        file_name for file_name in os.listdir(folder_path_str)\n",
        "        if file_name.lower().endswith((\".mp4\", \".mkv\", \".avi\", \".mov\"))\n",
        "    ]\n",
        "    print(f\"[EXTRACTION [INFO ℹ️]] Se encontraron {len(video_files_list)} archivos de video.\", flush=True)\n",
        "\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        status_data_list = []\n",
        "        for video_file_str in video_files_list:\n",
        "            status_str = \"Transcrito\" if video_file_str in processed_files_dic else \"No transcrito\"\n",
        "            date_str = processed_files_dic.get(video_file_str, \"N/A\")\n",
        "            status_data_list.append({\"file_name\": video_file_str, \"status\": status_str, \"transcription_date\": date_str})\n",
        "        status_df = pd.DataFrame(status_data_list)\n",
        "        print(\"\\n[METRICS [INFO ℹ️]] Estado de los vídeos:\", flush=True)\n",
        "        display(status_df)\n",
        "    except Exception as error_df:\n",
        "        print(f\"[METRICS [WARNING ⚠️]] No se pudo mostrar el DataFrame de estado: {error_df}\", flush=True)\n",
        "\n",
        "    # ────────────────────────────── CARGA DEL MODELO WHISPER ──────────────────────────────\n",
        "    try:\n",
        "        print(f\"[LOAD [START ▶️]] Cargando modelo Whisper '{model_size_str}'...\", flush=True)\n",
        "        from whisper import load_model\n",
        "        model = load_model(model_size_str)\n",
        "        print(f\"[LOAD [SUCCESS ✅]] Modelo '{model_size_str}' cargado correctamente.\", flush=True)\n",
        "    except Exception as error_model:\n",
        "        raise Exception(f\"[LOAD [ERROR ❌]] Error al cargar el modelo Whisper: {error_model}\")\n",
        "\n",
        "    max_chars_int = 50000  # Máximo de caracteres por bloque\n",
        "\n",
        "    # ────────────────────────────── PROCESAMIENTO DE CADA VIDEO ──────────────────────────────\n",
        "    for video_file_str in video_files_list:\n",
        "        if video_file_str in processed_files_dic:\n",
        "            if verbose_bool:\n",
        "                print(f\"[TRANSFORMATION [INFO ℹ️]] Saltando archivo ya procesado: {video_file_str}\", flush=True)\n",
        "            continue\n",
        "\n",
        "        video_path_str = os.path.join(folder_path_str, video_file_str)\n",
        "        properties_dic = _get_video_properties_dic(video_path_str)\n",
        "\n",
        "        # ────────────────────────────── TRANSCRIPCIÓN DEL VIDEO ──────────────────────────────\n",
        "        transcription_str = \"\"\n",
        "        try:\n",
        "            print(f\"[TRANSFORMATION [START ▶️]] Transcribiendo: {video_file_str}\", flush=True)\n",
        "            result_dic = model.transcribe(video_path_str, language='es')\n",
        "            transcription_str = result_dic.get(\"text\", \"\")\n",
        "            print(f\"[TRANSFORMATION [SUCCESS ✅]] Transcripción completada: {video_file_str}\", flush=True)\n",
        "        except Exception as error_trans:\n",
        "            print(f\"[TRANSFORMATION [ERROR ❌]] Error transcribiendo {video_file_str}: {error_trans}\", flush=True)\n",
        "            transcription_str = \"\"\n",
        "\n",
        "        # Troceo de la transcripción en bloques de 50k caracteres, limitado a 10 partes\n",
        "        transcription_parts_list = [\n",
        "            transcription_str[i : i + max_chars_int]\n",
        "            for i in range(0, len(transcription_str), max_chars_int)\n",
        "        ]\n",
        "        if len(transcription_parts_list) > 10:\n",
        "            sobrante_str = \"\".join(transcription_parts_list[10:])\n",
        "            transcription_parts_list[9] += sobrante_str\n",
        "            transcription_parts_list = transcription_parts_list[:10]\n",
        "        transcription_parts_list += [\"\"] * (10 - len(transcription_parts_list))\n",
        "\n",
        "        # Construcción de la fila para la hoja de cálculo\n",
        "        row_values_list = [\n",
        "            properties_dic.get(\"file_name\"),\n",
        "            properties_dic.get(\"file_path\"),\n",
        "            properties_dic.get(\"file_size_mb\"),\n",
        "            properties_dic.get(\"duration_s\"),\n",
        "            properties_dic.get(\"video_codec\"),\n",
        "            properties_dic.get(\"audio_codec\"),\n",
        "            properties_dic.get(\"resolution\"),\n",
        "            properties_dic.get(\"audio_sample_rate\"),\n",
        "            datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        ] + transcription_parts_list\n",
        "\n",
        "        # ────────────────────────────── ACTUALIZACIÓN EN GOOGLE SHEETS ──────────────────────────────\n",
        "        reintentos_int = 3\n",
        "        for intento_int in range(reintentos_int):\n",
        "            try:\n",
        "                sheet.append_row(row_values_list, value_input_option=\"USER_ENTERED\")\n",
        "                if verbose_bool:\n",
        "                    print(f\"[LOAD [SUCCESS ✅]] Actualizado en Google Sheets: {video_file_str}\", flush=True)\n",
        "                break\n",
        "            except Exception as error_append:\n",
        "                if intento_int < reintentos_int - 1:\n",
        "                    print(f\"[LOAD [WARNING ⚠️]] Error al actualizar Google Sheets. Reintentando ({intento_int + 1}/{reintentos_int})...\", flush=True)\n",
        "                    time.sleep(5)\n",
        "                else:\n",
        "                    print(f\"[LOAD [ERROR ❌]] Error persistente al actualizar Google Sheets: {error_append}\", flush=True)\n",
        "\n",
        "    print(f\"\\n[END [FINISHED ✅]] Proceso completado. Hoja de cálculo disponible en: {spreadsheet.url}\", flush=True)\n"
      ],
      "metadata": {
        "id": "vi0G1btEOo6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title TRANSCRIBE A SPREADSHEET\n",
        "params_colab = {\n",
        "    \"folder_path\": \"/content/drive/Shareddrives/AREA ACADEMICO/MOCADI/Vídeo Correcciones  /Animación de Personajes 3D - Aca 1 - L06/NIVEL BAJO\",\n",
        "    \"model_size\": \"small\",\n",
        "    \"sheet_id\": \"1kr0WWfXQmiluErKkA0SUP7e9IYXqhKGTznazvsdfRbA\",                         # ID de la hoja de Google\n",
        "    \"verbose\": True,\n",
        "\n",
        "    \"ini_environment_identificated\": ini_environment_identificated,\n",
        "    \"json_keyfile_local\": GCP_json_keyfile_local,\n",
        "    \"json_keyfile_colab\": GCP_json_keyfile_colab,\n",
        "    \"json_keyfile_GCP_secret_id\": GCP_json_keyfile_GCP_secret_id,\n",
        "}\n",
        "\n",
        "video_whisper_transcribe_to(params_colab)"
      ],
      "metadata": {
        "id": "TNuwx8lqPm13",
        "outputId": "1409d1ea-1aaa-4836-868e-6434fa50517c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[START ▶️] Inicio del proceso de transcripción de videos.\n",
            "[AUTHENTICATION [START ▶️]] Iniciando autenticación en entorno COLAB mediante JSON de credenciales...\n",
            "[AUTHENTICATION [SUCCESS ✅]] Autenticación en entorno COLAB completada.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "[LOAD [ERROR ❌]] Error al acceder/crear la hoja de cálculo: ('invalid_scope: Invalid OAuth scope or ID token audience provided.', {'error': 'invalid_scope', 'error_description': 'Invalid OAuth scope or ID token audience provided.'})",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRefreshError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-68c017b6f596>\u001b[0m in \u001b[0;36mvideo_whisper_transcribe_to\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msheet_id_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mspreadsheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgspread_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_by_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet_id_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LOAD [INFO ℹ️]] Hoja encontrada con ID: {sheet_id_str}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/client.py\u001b[0m in \u001b[0;36mopen_by_key\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mspreadsheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpreadsheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAPIError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/spreadsheet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, http_client, properties)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_sheet_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_properties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"properties\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/spreadsheet.py\u001b[0m in \u001b[0;36mfetch_sheet_metadata\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_sheet_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/http_client.py\u001b[0m in \u001b[0;36mfetch_sheet_metadata\u001b[0;34m(self, id, params)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gspread/http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, params, data, json, files, headers)\u001b[0m\n\u001b[1;32m    113\u001b[0m     ) -> Response:\n\u001b[0;32m--> 114\u001b[0;31m         response = self.session.request(\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0mremaining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/credentials.py\u001b[0m in \u001b[0;36mbefore_request\u001b[0;34m(self, request, method, url, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/credentials.py\u001b[0m in \u001b[0;36m_blocking_refresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/service_account.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0massertion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_authorization_grant_assertion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             access_token, expiry, _ = _client.jwt_grant(\n\u001b[0m\u001b[1;32m    449\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massertion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36mjwt_grant\u001b[0;34m(request, token_uri, assertion, can_retry)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     response_data = _token_endpoint_request(\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36m_token_endpoint_request\u001b[0;34m(request, token_uri, body, access_token, use_json, can_retry, headers, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse_status_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0m_handle_error_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretryable_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36m_handle_error_response\u001b[0;34m(response_data, retryable_error)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     raise exceptions.RefreshError(\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0merror_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretryable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretryable_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRefreshError\u001b[0m: ('invalid_scope: Invalid OAuth scope or ID token audience provided.', {'error': 'invalid_scope', 'error_description': 'Invalid OAuth scope or ID token audience provided.'})",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4b89dc466af2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mvideo_whisper_transcribe_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_colab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-68c017b6f596>\u001b[0m in \u001b[0;36mvideo_whisper_transcribe_to\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LOAD [INFO ℹ️]] Hoja creada: {spreadsheet.title}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_sheet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LOAD [ERROR ❌]] Error al acceder/crear la hoja de cálculo: {error_sheet}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspreadsheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: [LOAD [ERROR ❌]] Error al acceder/crear la hoja de cálculo: ('invalid_scope: Invalid OAuth scope or ID token audience provided.', {'error': 'invalid_scope', 'error_description': 'Invalid OAuth scope or ID token audience provided.'})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title scrap_videofiles_local_dir_to_gspread()\n",
        "def scrap_videofiles_local_dir_to_gspread(params: dict) -> None:\n",
        "    \"\"\"\n",
        "    Busca archivos de video en una carpeta, ya sea en un sistema de archivos local o en Google Drive,\n",
        "    extrae sus propiedades técnicas y envía los resultados a una hoja de Google Sheets.\n",
        "\n",
        "    La estrategia de búsqueda se selecciona según el valor de 'ini_environment_identificated' y la existencia\n",
        "    de la ruta en el sistema de archivos. Si la ruta existe localmente, se realiza un escaneo con os.walk;\n",
        "    de lo contrario, se asume que se trata de una ruta de Google Drive y se utiliza la API de Drive para listar archivos.\n",
        "\n",
        "    Args:\n",
        "        params (dict):\n",
        "            - video_files_root_path (str): Ruta del directorio raíz o URL del folder de Google Drive.\n",
        "            - video_files_target_search_folder (list): Lista de subcarpetas de interés dentro del directorio raíz.\n",
        "            - video_files_target_search_extension (list): Lista de extensiones de archivo a buscar (ej.: [\".mp4\"]).\n",
        "            - ini_environment_identificated (str): Identificador del entorno. Ej.: \"LOCAL\", \"COLAB\", \"COLAB_ENTERPRISE\", etc.\n",
        "            - json_keyfile_local (str): Ruta al archivo JSON de credenciales para entornos LOCAL.\n",
        "            - json_keyfile_colab (str): Ruta al archivo JSON de credenciales para entornos COLAB.\n",
        "            - json_keyfile_GCP_secret_id (str): Secret ID del JSON de credenciales en Secret Manager (para entornos GCP).\n",
        "            - destination_files_path_table_spreadsheet_url (str): URL de la hoja de Google Sheets destino.\n",
        "            - destination_files_path_table_spreadsheet_worksheet (str): Nombre de la pestaña en la hoja destino.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        ValueError: Si falta algún parámetro obligatorio o no se encuentran archivos.\n",
        "        Exception: Si ocurre un error al interactuar con Google Sheets.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import re\n",
        "    import subprocess\n",
        "    import json\n",
        "    import pandas as pd\n",
        "    from datetime import datetime\n",
        "    from time import time\n",
        "    from dpm_google import gspread_initialize_client, gspread_df_to_sheet\n",
        "    from googleapiclient.discovery import build  # Para Drive API\n",
        "\n",
        "    print(\"\\n[START ▶️] Inicio del proceso de scrap de videos a Google Sheets.\\n\", flush=True)\n",
        "    start_time_float = time()\n",
        "\n",
        "    # ────────────────────────────── VALIDACIÓN DE PARÁMETROS ──────────────────────────────\n",
        "    video_files_root_path_str = params.get('video_files_root_path')\n",
        "    target_folders_list = params.get('video_files_target_search_folder', [])\n",
        "    file_exts_list = params.get('video_files_target_search_extension', [])\n",
        "    ini_env_str = params.get(\"ini_environment_identificated\")\n",
        "    json_keyfile_local_str = params.get(\"json_keyfile_local\")\n",
        "    json_keyfile_colab_str = params.get(\"json_keyfile_colab\")\n",
        "    json_keyfile_GCP_secret_id_str = params.get(\"json_keyfile_GCP_secret_id\")\n",
        "    spreadsheet_url_str = params.get('destination_files_path_table_spreadsheet_url')\n",
        "    worksheet_name_str = params.get('destination_files_path_table_spreadsheet_worksheet')\n",
        "\n",
        "    if not video_files_root_path_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] El parámetro 'video_files_root_path' es obligatorio.\")\n",
        "    if not file_exts_list:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] El parámetro 'video_files_target_search_extension' es obligatorio y debe contener al menos una extensión.\")\n",
        "    if not ini_env_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] El parámetro 'ini_environment_identificated' es obligatorio.\")\n",
        "    if not json_keyfile_local_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] El parámetro 'json_keyfile_local' es obligatorio.\")\n",
        "    if not json_keyfile_colab_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] El parámetro 'json_keyfile_colab' es obligatorio.\")\n",
        "    if not json_keyfile_GCP_secret_id_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] El parámetro 'json_keyfile_GCP_secret_id' es obligatorio.\")\n",
        "    if not spreadsheet_url_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] El parámetro 'destination_files_path_table_spreadsheet_url' es obligatorio.\")\n",
        "    if not worksheet_name_str:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] El parámetro 'destination_files_path_table_spreadsheet_worksheet' es obligatorio.\")\n",
        "\n",
        "    print(\"[INFO ℹ️] Parámetros validados correctamente.\\n\", flush=True)\n",
        "\n",
        "    # ────────────────────────────── SELECCIÓN DE MÉTODO DE BÚSQUEDA ──────────────────────────────\n",
        "    # Si la ruta existe localmente, se utiliza os.walk. De lo contrario, se asume que es una ruta de Google Drive.\n",
        "    def _find_files_in_folders(root_str: str, folders_list: list, exts_list: list) -> pd.DataFrame:\n",
        "        results_list = []\n",
        "        for dirpath, dirnames, filenames in os.walk(root_str):\n",
        "            current_folder_str = os.path.basename(dirpath)\n",
        "            if folders_list and current_folder_str not in folders_list:\n",
        "                continue\n",
        "            for file_str in filenames:\n",
        "                _, file_ext_str = os.path.splitext(file_str)\n",
        "                if file_ext_str.lower() in [ext.lower() for ext in exts_list]:\n",
        "                    file_path_str = os.path.join(dirpath, file_str)\n",
        "                    results_list.append({\n",
        "                        \"video_file_path\": file_path_str,\n",
        "                        \"video_file_name\": file_str\n",
        "                    })\n",
        "                    print(f\"[INFO ℹ️] ➤ Archivo encontrado: {file_str} (Ruta: {file_path_str})\", flush=True)\n",
        "        if not results_list:\n",
        "            print(\"[WARNING ⚠️] No se encontraron archivos que coincidan con los criterios especificados.\\n\", flush=True)\n",
        "            return pd.DataFrame()\n",
        "        return pd.DataFrame(results_list)\n",
        "\n",
        "    def _find_files_in_drive(folder_url: str, exts_list: list, creds) -> pd.DataFrame:\n",
        "        # Se asume que folder_url es la URL de la carpeta en Drive; se extrae el ID.\n",
        "        m = re.search(r'/d/([a-zA-Z0-9_-]+)', folder_url)\n",
        "        folder_id = m.group(1) if m else folder_url\n",
        "        drive_service = build('drive', 'v3', credentials=creds)\n",
        "        query = f\"'{folder_id}' in parents and trashed = false\"\n",
        "        results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "        files = results.get('files', [])\n",
        "        results_list = []\n",
        "        for f in files:\n",
        "            name = f.get('name', '')\n",
        "            _, file_ext_str = os.path.splitext(name)\n",
        "            if file_ext_str.lower() in [ext.lower() for ext in exts_list]:\n",
        "                results_list.append({\n",
        "                    \"video_file_path\": f.get('id'),  # Para Drive se usa el ID del archivo\n",
        "                    \"video_file_name\": name\n",
        "                })\n",
        "                print(f\"[INFO ℹ️] ➤ Archivo encontrado: {name} (Drive ID: {f.get('id')})\", flush=True)\n",
        "        if not results_list:\n",
        "            print(\"[WARNING ⚠️] No se encontraron archivos en Drive que coincidan con los criterios.\", flush=True)\n",
        "            return pd.DataFrame()\n",
        "        return pd.DataFrame(results_list)\n",
        "\n",
        "    # Se requiere autenticar previamente para usar tanto Sheets como Drive.\n",
        "    # Aquí reutilizamos el cliente de Sheets (gspread) que se inicializará más adelante para obtener las credenciales.\n",
        "    # Para el listado en Drive, se crearán a partir del mismo método de autenticación en gspread_initialize_client.\n",
        "    drive_scan_required = not os.path.exists(video_files_root_path_str)\n",
        "    if drive_scan_required:\n",
        "        print(f\"[INFO ℹ️] La ruta '{video_files_root_path_str}' no se encontró localmente; se asume que es una ruta de Google Drive.\\n\", flush=True)\n",
        "    else:\n",
        "        print(f\"[INFO ℹ️] Se encontró la ruta local '{video_files_root_path_str}'. Usando búsqueda local.\\n\", flush=True)\n",
        "\n",
        "    # ────────────────────────────── AUTENTICACIÓN PARA GOOGLE SHEETS Y DRIVE ──────────────────────────────\n",
        "    # Se utiliza la estrategia de autenticación definida por las nuevas keys.\n",
        "    client = gspread_initialize_client({\n",
        "        \"ini_environment_identificated\": ini_env_str,\n",
        "        \"json_keyfile_local\": json_keyfile_local_str,\n",
        "        \"json_keyfile_colab\": json_keyfile_colab_str,\n",
        "        \"json_keyfile_GCP_secret_id\": json_keyfile_GCP_secret_id_str\n",
        "    })\n",
        "    if not client:\n",
        "        raise Exception(\"[AUTHENTICATION [ERROR ❌]] No se pudo autenticar con Google Sheets.\")\n",
        "    print(\"[SUCCESS ✅] Cliente autenticado correctamente.\\n\", flush=True)\n",
        "    # Extraer las credenciales del cliente para usarlas con la API de Drive.\n",
        "    creds = client.auth.token  if hasattr(client, \"auth\") else None\n",
        "\n",
        "    # ────────────────────────────── OBTENCIÓN DE ARCHIVOS ──────────────────────────────\n",
        "    if drive_scan_required:\n",
        "        df_paths = _find_files_in_drive(video_files_root_path_str, file_exts_list, client.auth.credentials)\n",
        "    else:\n",
        "        df_paths = _find_files_in_folders(video_files_root_path_str, target_folders_list, file_exts_list)\n",
        "\n",
        "    if df_paths.empty:\n",
        "        raise ValueError(\"[VALIDATION [ERROR ❌]] No se encontraron archivos que coincidan con los criterios especificados.\")\n",
        "    print(f\"[INFO ℹ️] Total de archivos encontrados: {len(df_paths)}\\n\", flush=True)\n",
        "\n",
        "    # ────────────────────────────── EXTRACCIÓN DE PROPIEDADES DE VIDEO ──────────────────────────────\n",
        "    def _extract_video_properties(file_path_str: str) -> dict:\n",
        "        try:\n",
        "            # En Drive, dado que solo tenemos el ID, se requeriría descargar el archivo; aquí se asume que\n",
        "            # los archivos locales se procesan con ffprobe. Para Drive, se debería implementar la descarga previa.\n",
        "            if drive_scan_required:\n",
        "                raise NotImplementedError(\"La extracción de propiedades para archivos en Drive requiere descarga previa.\")\n",
        "            file_size_int = os.path.getsize(file_path_str) // (1024 * 1024)\n",
        "            result = subprocess.run([\n",
        "                'ffprobe', '-v', 'error', '-print_format', 'json', '-show_streams', '-show_format', file_path_str\n",
        "            ], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "            info_dic = json.loads(result.stdout)\n",
        "            video_codec_str = audio_codec_str = None\n",
        "            video_bitrate_int = audio_bitrate_int = 0\n",
        "            video_width_int = video_height_int = None\n",
        "            video_fps_float = None\n",
        "            audio_channels_int = audio_sample_rate_int = None\n",
        "            duration_float = 0.0\n",
        "\n",
        "            if 'streams' in info_dic:\n",
        "                for stream in info_dic['streams']:\n",
        "                    if stream.get('codec_type') == 'video':\n",
        "                        video_codec_str = stream.get('codec_name')\n",
        "                        video_bitrate_int = int(stream.get('bit_rate', 0)) // 1000\n",
        "                        video_width_int = stream.get('width')\n",
        "                        video_height_int = stream.get('height')\n",
        "                        if 'r_frame_rate' in stream:\n",
        "                            num_int, den_int = map(int, stream['r_frame_rate'].split('/'))\n",
        "                            video_fps_float = num_int / den_int if den_int != 0 else None\n",
        "                    elif stream.get('codec_type') == 'audio':\n",
        "                        audio_codec_str = stream.get('codec_name')\n",
        "                        audio_bitrate_int = int(stream.get('bit_rate', 0)) // 1000\n",
        "                        audio_channels_int = stream.get('channels')\n",
        "                        audio_sample_rate_int = int(stream.get('sample_rate', 0))\n",
        "            if 'format' in info_dic:\n",
        "                duration_float = float(info_dic['format'].get('duration', 0))\n",
        "                duration_ms_int = int(duration_float * 1000)\n",
        "                duration_hms_str = \"{:02d}:{:02d}:{:02d}\".format(\n",
        "                    int(duration_float) // 3600, (int(duration_float) % 3600) // 60, int(duration_float) % 60\n",
        "                )\n",
        "            else:\n",
        "                duration_ms_int = 0\n",
        "                duration_hms_str = \"00:00:00\"\n",
        "\n",
        "            return {\n",
        "                \"file_name\": os.path.basename(file_path_str),\n",
        "                \"file_path\": file_path_str,\n",
        "                \"file_creation_date\": datetime.fromtimestamp(os.path.getctime(file_path_str)).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"file_last_modified_date\": datetime.fromtimestamp(os.path.getmtime(file_path_str)).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"file_scrap_date\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"file_size_mb\": file_size_int,\n",
        "                \"duration_hms\": duration_hms_str,\n",
        "                \"duration_ms\": duration_ms_int,\n",
        "                \"video_codec\": video_codec_str,\n",
        "                \"video_bitrate_kbps\": video_bitrate_int,\n",
        "                \"video_fps\": video_fps_float,\n",
        "                \"video_resolution\": f\"{video_width_int}x{video_height_int}\" if video_width_int and video_height_int else None,\n",
        "                \"audio_codec\": audio_codec_str,\n",
        "                \"audio_bitrate_kbps\": audio_bitrate_int,\n",
        "                \"audio_channels\": audio_channels_int,\n",
        "                \"audio_sample_rate_hz\": audio_sample_rate_int,\n",
        "            }\n",
        "        except Exception as error_prop:\n",
        "            print(f\"[EXTRACTION [ERROR ❌]] Error al obtener propiedades del video: {error_prop}\", flush=True)\n",
        "            return {\n",
        "                \"file_name\": os.path.basename(file_path_str),\n",
        "                \"file_path\": file_path_str,\n",
        "                \"file_creation_date\": \"unknown\",\n",
        "                \"file_last_modified_date\": \"unknown\",\n",
        "                \"file_scrap_date\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"file_size_mb\": 0,\n",
        "                \"duration_hms\": \"00:00:00\",\n",
        "                \"duration_ms\": 0,\n",
        "                \"video_codec\": \"unknown\",\n",
        "                \"video_bitrate_kbps\": 0,\n",
        "                \"video_fps\": 0,\n",
        "                \"video_resolution\": \"unknown\",\n",
        "                \"audio_codec\": \"unknown\",\n",
        "                \"audio_bitrate_kbps\": 0,\n",
        "                \"audio_channels\": 0,\n",
        "                \"audio_sample_rate_hz\": 0,\n",
        "            }\n",
        "\n",
        "    print(\"[START ▶️] Extrayendo propiedades de los videos...\\n\", flush=True)\n",
        "    df_video_props = df_paths['video_file_path'].apply(_extract_video_properties).apply(pd.Series)\n",
        "    print(\"[SUCCESS ✅] Propiedades extraídas correctamente.\\n\", flush=True)\n",
        "\n",
        "    df_paths_properties = df_video_props[[\n",
        "        \"file_name\",\n",
        "        \"file_path\",\n",
        "        \"file_creation_date\",\n",
        "        \"file_last_modified_date\",\n",
        "        \"file_scrap_date\",\n",
        "        \"file_size_mb\",\n",
        "        \"duration_hms\",\n",
        "        \"duration_ms\",\n",
        "        \"video_codec\",\n",
        "        \"video_bitrate_kbps\",\n",
        "        \"video_fps\",\n",
        "        \"video_resolution\",\n",
        "        \"audio_codec\",\n",
        "        \"audio_bitrate_kbps\",\n",
        "        \"audio_channels\",\n",
        "        \"audio_sample_rate_hz\",\n",
        "    ]]\n",
        "\n",
        "    # ────────────────────────────── RESPALDO LOCAL ──────────────────────────────\n",
        "    backup_csv_path_str = \"video_files_backup.csv\"\n",
        "    df_paths_properties.to_csv(backup_csv_path_str, index=False)\n",
        "    print(f\"[INFO ℹ️] Datos respaldados localmente en: {backup_csv_path_str}\\n\", flush=True)\n",
        "\n",
        "    # ────────────────────────────── ESTADÍSTICAS ──────────────────────────────\n",
        "    total_videos_int = len(df_paths_properties)\n",
        "    print(f\"[METRICS [INFO ℹ️]] Número total de videos procesados: {total_videos_int}\", flush=True)\n",
        "    process_duration_float = time() - start_time_float\n",
        "    print(f\"[METRICS [INFO ℹ️]] Duración total del proceso: {process_duration_float:.2f} segundos\\n\", flush=True)\n",
        "\n",
        "    # ────────────────────────────── ENVÍO A GOOGLE SHEETS ──────────────────────────────\n",
        "    print(\"[START ▶️] Enviando datos a Google Sheets...\\n\", flush=True)\n",
        "    gspread_df_to_sheet({\n",
        "        'client': client,\n",
        "        'spreadsheet_url': spreadsheet_url_str,\n",
        "        'worksheet_name': worksheet_name_str,\n",
        "        'df': df_paths_properties,\n",
        "        'row_filter_list': list(range(len(df_paths_properties))),\n",
        "        'col_filter_list': '',\n",
        "        'include_header': True\n",
        "    })\n",
        "    print(\"[SUCCESS ✅] Datos enviados exitosamente.\\n\", flush=True)\n",
        "\n",
        "    os.remove(backup_csv_path_str)\n",
        "    print(f\"[INFO ℹ️] Respaldo local eliminado: {backup_csv_path_str}\\n\", flush=True)\n",
        "    print(\"[END [FINISHED ✅]] Proceso completado.\\n\", flush=True)\n"
      ],
      "metadata": {
        "id": "mCGdqT0nY9w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title PATH FILES A SPREADSHEET\n",
        "# Ejemplo de uso para scrap_videofiles_local_dir_to_gspread()\n",
        "\n",
        "params_example = {\n",
        "    \"video_files_root_path\": \"/content/drive/MyDrive/Videos\",\n",
        "       # Puede ser una ruta local (ej.: \"C:/videos\") o una URL de carpeta de Google Drive (ej.: \"https://drive.google.com/drive/folders/ID_FOLDER\")\n",
        "    \"video_files_target_search_folder\": [\"Subcarpeta1\", \"Subcarpeta2\"],  # Subcarpetas de interés (opcional)\n",
        "    \"video_files_target_search_extension\": [\".mp4\", \".mkv\"],            # Extensiones de video a buscar\n",
        "\n",
        "    \"ini_environment_identificated\": ini_environment_identificated,\n",
        "       # Ej.: \"LOCAL\" para escanear localmente o \"DRIVE\" (u otro valor distinto a \"LOCAL\") para escanear Google Drive\n",
        "    \"json_keyfile_local\": GCP_json_keyfile_local,                        # Ruta al JSON de credenciales para LOCAL\n",
        "    \"json_keyfile_colab\": GCP_json_keyfile_colab,                        # Ruta al JSON de credenciales para COLAB\n",
        "    \"json_keyfile_GCP_secret_id\": GCP_json_keyfile_GCP_secret_id,          # Secret ID para autenticación en GCP\n",
        "\n",
        "    \"destination_files_path_table_spreadsheet_url\": \"https://docs.google.com/spreadsheets/d/ID_HOJA_DESTINO\",\n",
        "    \"destination_files_path_table_spreadsheet_worksheet\": \"Videos\"       # Nombre de la pestaña destino\n",
        "}\n",
        "\n",
        "scrap_videofiles_local_dir_to_gspread(params_example)\n"
      ],
      "metadata": {
        "id": "VwLiEDRzZBgr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnJRTd3dG+aGsCNKPPgNS1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}